{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "791f8d99-e7a3-45f3-8a06-340e55945722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from IPython.display import display, HTML\n",
    "import numpy as np\n",
    "import ast\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import Word2Vec\n",
    "from collections import Counter\n",
    "from numpy.linalg import norm\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eb8e160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_clusters_ordenados(etiquetas):\n",
    "    # Contar el número de documentos por clúster\n",
    "    conteo_clusters = Counter(etiquetas)\n",
    "\n",
    "    # Eliminar el clúster residual (-1)\n",
    "    #del conteo_clusters[-1]\n",
    "\n",
    "    # Ordenar por número de documentos (de mayor a menor)\n",
    "    clusters_ordenados = sorted(conteo_clusters.items(), key=lambda x: x[1], reverse=True)\n",
    "    return clusters_ordenados\n",
    "\n",
    "def filter_documents_for_dictionary(tokenized_documents, filtered_words):\n",
    "    filtered_documents = []\n",
    "    for doc in tokenized_documents:\n",
    "        filtered_doc = [word for word in doc if word in filtered_words]\n",
    "        filtered_documents.append(filtered_doc)\n",
    "    return filtered_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a2be601",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('etiquetas_meta_HDBSCAN.pkl', 'rb') as archivo:\n",
    "    etiquetas_meta_documentos = pickle.load(archivo)\n",
    "df_preprocesado = pd.read_csv('df_preprocesado.csv', sep=\";\")\n",
    "dictionary = Dictionary.load('dictionary_filtrado_spacy.gensim')\n",
    "filtered_words = set(dictionary.token2id.keys())\n",
    "preprocesado_documents=df_preprocesado['texto_preprocesado'].apply(ast.literal_eval)\n",
    "# Generar documentos en igual de condiciones\n",
    "documents = filter_documents_for_dictionary(preprocesado_documents,filtered_words)\n",
    "modelo_w2v_cargado = Word2Vec.load(\"w2v_250_epochs.model\")\n",
    "documentos_originales=df_preprocesado['texto']\n",
    "clusters_ordenados = obtener_clusters_ordenados(etiquetas_meta_documentos)\n",
    "cluster_sizes_dict = dict(clusters_ordenados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23d4f40c-82e7-4761-bd9b-b3d5eeafa77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_palabras_representativas_w2v2_con_pesos_normalizados(model_w2v, documents, labels, n=10):\n",
    "    cluster_palabras_representativas = {}\n",
    "\n",
    "    for cluster_label in np.unique(labels):\n",
    "        cluster_indices = np.where(labels == cluster_label)[0]\n",
    "        cluster_documentos = [documents[i] for i in cluster_indices]\n",
    "\n",
    "        # Obtener embeddings promedio de palabras por documento\n",
    "        cluster_vectores = []\n",
    "        for doc in cluster_documentos:\n",
    "            palabra_vectors = [model_w2v.wv[palabra] for palabra in doc if palabra in model_w2v.wv]\n",
    "            if palabra_vectors:  # Evitar documentos vacíos\n",
    "                cluster_vectores.append(np.mean(palabra_vectors, axis=0))\n",
    "\n",
    "        if not cluster_vectores:\n",
    "            cluster_palabras_representativas[cluster_label] = []\n",
    "            continue\n",
    "\n",
    "        # Calcular el promedio del clúster\n",
    "        cluster_centroide = np.mean(cluster_vectores, axis=0)\n",
    "\n",
    "        # Encontrar palabras más similares al promedio\n",
    "        try:\n",
    "            palabras_cercanas = model_w2v.wv.similar_by_vector(cluster_centroide, topn=n)\n",
    "            palabras_con_pesos = []\n",
    "\n",
    "            # Calcular los pesos proporcionalmente a la proximidad al centroide\n",
    "            for palabra, score in palabras_cercanas:\n",
    "                peso = score  # El peso puede ser directamente la similitud\n",
    "                palabras_con_pesos.append((palabra, peso))\n",
    "\n",
    "            # Normalizar los pesos para que su suma sea igual al tamaño del clúster\n",
    "            total_peso = sum(peso for _, peso in palabras_con_pesos)\n",
    "            total_documentos = len(cluster_documentos)  # Tamaño del clúster\n",
    "            palabras_con_pesos_dobles = [(palabra, peso, (peso / total_peso) * total_documentos) for palabra, peso in palabras_cercanas]\n",
    "            cluster_palabras_representativas[cluster_label] = palabras_con_pesos_dobles\n",
    "\n",
    "        except Exception as e:\n",
    "            cluster_palabras_representativas[cluster_label] = []\n",
    "\n",
    "    return cluster_palabras_representativas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7ae8640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construir_documentos_representativos_para_treemap_ponderado(\n",
    "    cluster_keywords_weights,\n",
    "    etiquetas_predichas,\n",
    "    documentos_preprocesados,\n",
    "    documentos_originales,\n",
    "    modelo_w2v,\n",
    "    num_documentos=5\n",
    "):\n",
    "    documentos_representativos = {}\n",
    "\n",
    "    for cluster_id, lista_palabras in cluster_keywords_weights.items():\n",
    "        documentos_representativos[cluster_id] = {}\n",
    "\n",
    "        for palabra, peso_real, peso_palabra in lista_palabras:\n",
    "            if palabra not in modelo_w2v.wv:\n",
    "                continue\n",
    "\n",
    "            vector_objetivo = modelo_w2v.wv[palabra]\n",
    "            docs_similares = []\n",
    "\n",
    "            for i, (etiqueta, doc) in enumerate(zip(etiquetas_predichas, documentos_preprocesados)):\n",
    "                if etiqueta != cluster_id:\n",
    "                    continue\n",
    "\n",
    "                vectores_doc = [modelo_w2v.wv[p] for p in doc if p in modelo_w2v.wv]\n",
    "                if not vectores_doc:\n",
    "                    continue\n",
    "\n",
    "                vector_promedio = np.mean(vectores_doc, axis=0)\n",
    "                similitud = np.dot(vector_promedio, vector_objetivo) / (\n",
    "                    norm(vector_promedio) * norm(vector_objetivo)\n",
    "                )\n",
    "\n",
    "                doc_resumen = documentos_originales[i][:100] + \"...\"\n",
    "                docs_similares.append((doc_resumen, similitud))\n",
    "\n",
    "            # Ordenar y limitar a los documentos más similares\n",
    "            docs_similares = sorted(docs_similares, key=lambda x: x[1], reverse=True)[:num_documentos]\n",
    "\n",
    "            # Normalizar similitudes para que sumen 1 y repartir el peso_palabra\n",
    "            suma_similitudes = sum(sim for _, sim in docs_similares)\n",
    "            if suma_similitudes > 0:\n",
    "                docs_ponderados = [\n",
    "                    (doc, sim,(sim / suma_similitudes) * peso_palabra)\n",
    "                    for doc, sim in docs_similares\n",
    "                ]\n",
    "                documentos_representativos[cluster_id][palabra] = docs_ponderados\n",
    "\n",
    "    return documentos_representativos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86c06130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportar_treemap_clusters_palabras_documentos_go_tooltip(\n",
    "    cluster_sizes,\n",
    "    cluster_keywords_weights,\n",
    "    documentos_representativos,\n",
    "    output_filename=\"treemap_clusters_palabras_documentos.html\",\n",
    "    nombres_clusters=None  # Nuevo parámetro opcional\n",
    "):\n",
    "    labels = []\n",
    "    parents = []\n",
    "    values = []\n",
    "    hover_texts = []\n",
    "\n",
    "    for cluster_id, size in cluster_sizes.items():\n",
    "        # Usar nombre representativo si está disponible, si no, usar \"Cluster {id}\"\n",
    "        cluster_name = nombres_clusters.get(cluster_id, f\"Cluster {cluster_id}\") if nombres_clusters else f\"Cluster {cluster_id}\"\n",
    "        \n",
    "        labels.append(cluster_name)\n",
    "        parents.append(\"\")\n",
    "        values.append(size)\n",
    "        hover_texts.append(f\"{cluster_name}<br>Tamaño: {size}\")\n",
    "\n",
    "        # Palabras clave dentro del clúster\n",
    "        for palabra, peso_real, peso_normalizado in cluster_keywords_weights[cluster_id]:\n",
    "            palabra_id = f\"{palabra} ({cluster_name})\"\n",
    "            labels.append(palabra_id)\n",
    "            parents.append(cluster_name)\n",
    "            values.append(peso_normalizado)\n",
    "            hover_texts.append(f\"Palabra: {palabra}<br>Relevancia: {peso_real:.2f}\")\n",
    "\n",
    "            # Documentos representativos de esa palabra\n",
    "            if cluster_id in documentos_representativos and palabra in documentos_representativos[cluster_id]:\n",
    "                for doc, peso_real_doc, peso_norm_doc in documentos_representativos[cluster_id][palabra]:\n",
    "                    doc_id = f\"{doc} ({palabra})\"\n",
    "                    labels.append(doc_id)\n",
    "                    parents.append(palabra_id)\n",
    "                    values.append(peso_norm_doc)\n",
    "                    hover_texts.append(f\"<b>Texto:</b><br>{doc}\"\n",
    "                                      f\"<b>Relevancia:</b> {peso_real_doc:.3f}\")\n",
    "\n",
    "    fig = go.Figure(go.Treemap(\n",
    "        labels=labels,\n",
    "        parents=parents,\n",
    "        values=values,\n",
    "        branchvalues=\"remainder\",\n",
    "        hovertext=hover_texts,\n",
    "        hoverinfo=\"text\"\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(title_text=\"Modelo de tópicos\", title_x=0.5)\n",
    "    fig.write_html(output_filename)\n",
    "    print(f\"Treemap exportado como {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5919e3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reasignar_clusters_por_tamaño(cluster_sizes_ordenado, cluster_keywords_weights):\n",
    "    # Paso 1: Crear el nuevo mapeo de etiquetas antiguas a nuevas, en orden decreciente de tamaño\n",
    "    claves_ordenadas = list(cluster_sizes_ordenado.keys())\n",
    "    mapeo_clusters = {clave_antigua: nueva_id for nueva_id, clave_antigua in enumerate(claves_ordenadas)}\n",
    "    \n",
    "    # Paso 2: Aplicar el mapeo a cluster_keywords_weights\n",
    "    nuevo_cluster_keywords_weights = {\n",
    "        mapeo_clusters[cluster_id]: palabras\n",
    "        for cluster_id, palabras in cluster_keywords_weights.items()\n",
    "        if cluster_id in mapeo_clusters\n",
    "    }\n",
    "    \n",
    "    return nuevo_cluster_keywords_weights, mapeo_clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f8a8dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reasignar_documentos_representativos(documentos_representativos, mapeo_clusters):\n",
    "    \"\"\"\n",
    "    Reasigna los IDs de cluster en el diccionario de documentos representativos\n",
    "    usando el mapeo de IDs antiguos a nuevos.\n",
    "    \n",
    "    Args:\n",
    "        documentos_representativos (dict): Diccionario con claves de cluster originales.\n",
    "        mapeo_clusters (dict): Diccionario que mapea ID antiguo → ID nuevo.\n",
    "\n",
    "    Returns:\n",
    "        dict: Nuevo diccionario con las claves reasignadas.\n",
    "    \"\"\"\n",
    "    nuevos_documentos = {\n",
    "        mapeo_clusters[cluster_id]: contenido\n",
    "        for cluster_id, contenido in documentos_representativos.items()\n",
    "        if cluster_id in mapeo_clusters\n",
    "    }\n",
    "    return nuevos_documentos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fb78f55-a881-4ea5-9636-495370c06eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_keywords_weights = obtener_palabras_representativas_w2v2_con_pesos_normalizados(\n",
    "    model_w2v=modelo_w2v_cargado,\n",
    "    documents=documents,\n",
    "    labels=np.array(etiquetas_meta_documentos),\n",
    "    n=10\n",
    "  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f33e1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "documentos_representativos = construir_documentos_representativos_para_treemap_ponderado(\n",
    "    cluster_keywords_weights,\n",
    "    etiquetas_meta_documentos,\n",
    "    documents,\n",
    "    documentos_originales,\n",
    "    modelo_w2v=modelo_w2v_cargado\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e348619",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevo_cluster_keywords_weights, mapeo_clusters = reasignar_clusters_por_tamaño(\n",
    "    cluster_sizes_dict, cluster_keywords_weights\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50bcacab",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevos_documentos_representativos = reasignar_documentos_representativos(\n",
    "    documentos_representativos, mapeo_clusters\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a9ac0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treemap exportado como treemap_temasv3.html\n"
     ]
    }
   ],
   "source": [
    "cluster_sizes_ordenado = {i: valor for i, (_, valor) in enumerate(list(cluster_sizes_dict.items())[:13])}\n",
    "cluster_sizes = cluster_sizes_ordenado\n",
    "cluster_keywords_weights=nuevo_cluster_keywords_weights\n",
    "documentos_representativos=nuevos_documentos_representativos\n",
    "nombres_clusters = {\n",
    "    0: \"Varios tipos Incidencias vía pública\",\n",
    "    1: \"Estado de la vía pública \",\n",
    "    2: \"Limpieza\",\n",
    "    3: \"Tráfico\",\n",
    "    4: \"Trámites y servicios\",\n",
    "    5: \"Juegos infantiles\",\n",
    "    6: \"Transporte público\",\n",
    "    7: \"Parques y jardines\",\n",
    "    8: \"Instalaciones municipales\",\n",
    "    9: \"Urbanismo\"\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "exportar_treemap_clusters_palabras_documentos_go_tooltip(\n",
    "    cluster_sizes,\n",
    "    cluster_keywords_weights,\n",
    "    documentos_representativos,\n",
    "    output_filename=\"treemap_temasv3.html\",\n",
    "    nombres_clusters=nombres_clusters\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
