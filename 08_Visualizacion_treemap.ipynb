{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c9eb985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import bz2\n",
    "from IPython.display import display, HTML\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "import ast\n",
    "from collections import Counter\n",
    "from numpy.linalg import norm\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1908428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_clusters_ordenados(etiquetas):\n",
    "    # Contar el número de documentos por clúster\n",
    "    conteo_clusters = Counter(etiquetas)\n",
    "\n",
    "    # Eliminar el clúster residual (-1)\n",
    "    #del conteo_clusters[-1]\n",
    "\n",
    "    # Ordenar por número de documentos (de mayor a menor)\n",
    "    clusters_ordenados = sorted(conteo_clusters.items(), key=lambda x: x[1], reverse=True)\n",
    "    return clusters_ordenados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ecd75b",
   "metadata": {},
   "source": [
    "### Datos necesarios para construir la visualización "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fa86835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# etiquetas generadas en el clustering\n",
    "with open('recursos/etiquetas_meta_HDBSCAN.pkl', 'rb') as archivo:\n",
    "    etiquetas_meta_documentos = pickle.load(archivo)\n",
    "# documentos preprocesados\n",
    "with open('recursos/documents.pkl', 'rb') as archivo:\n",
    "    documents = pickle.load(archivo)\n",
    "#documentos originales para ser mostrados    \n",
    "with bz2.BZ2File('recursos/documentos_originales.pkl.bz2', 'rb') as f:\n",
    "    documentos_originales = pickle.load(f)\n",
    "#modelo w2v generado    \n",
    "modelo_w2v_cargado = Word2Vec.load(\"recursos/w2v_250_epochs.model\")\n",
    "#obtener los clúster ordenados\n",
    "clusters_ordenados = obtener_clusters_ordenados(etiquetas_meta_documentos)\n",
    "cluster_sizes_dict = dict(clusters_ordenados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a1a22af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_palabras_representativas_w2v2_con_pesos_normalizados(model_w2v, documents, labels, n=10):\n",
    "    cluster_palabras_representativas = {}\n",
    "\n",
    "    for cluster_label in np.unique(labels):\n",
    "        cluster_indices = np.where(labels == cluster_label)[0]\n",
    "        cluster_documentos = [documents[i] for i in cluster_indices]\n",
    "\n",
    "        # Obtener embeddings promedio de palabras por documento\n",
    "        cluster_vectores = []\n",
    "        for doc in cluster_documentos:\n",
    "            palabra_vectors = [model_w2v.wv[palabra] for palabra in doc if palabra in model_w2v.wv]\n",
    "            if palabra_vectors:  # Evitar documentos vacíos\n",
    "                cluster_vectores.append(np.mean(palabra_vectors, axis=0))\n",
    "\n",
    "        if not cluster_vectores:\n",
    "            cluster_palabras_representativas[cluster_label] = []\n",
    "            continue\n",
    "\n",
    "        # Calcular el promedio del clúster\n",
    "        cluster_centroide = np.mean(cluster_vectores, axis=0)\n",
    "\n",
    "        # Encontrar palabras más similares al promedio\n",
    "        try:\n",
    "            palabras_cercanas = model_w2v.wv.similar_by_vector(cluster_centroide, topn=n)\n",
    "            palabras_con_pesos = []\n",
    "\n",
    "            # Calcular los pesos proporcionalmente a la proximidad al centroide\n",
    "            for palabra, score in palabras_cercanas:\n",
    "                peso = score  # El peso puede ser directamente la similitud\n",
    "                palabras_con_pesos.append((palabra, peso))\n",
    "\n",
    "            # Normalizar los pesos para que su suma sea igual al tamaño del clúster\n",
    "            total_peso = sum(peso for _, peso in palabras_con_pesos)\n",
    "            total_documentos = len(cluster_documentos)  # Tamaño del clúster\n",
    "            palabras_con_pesos_dobles = [(palabra, peso, (peso / total_peso) * total_documentos) for palabra, peso in palabras_cercanas]\n",
    "            cluster_palabras_representativas[cluster_label] = palabras_con_pesos_dobles\n",
    "\n",
    "        except Exception as e:\n",
    "            cluster_palabras_representativas[cluster_label] = []\n",
    "\n",
    "    return cluster_palabras_representativas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e384846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construir_documentos_representativos_para_treemap_ponderado(\n",
    "    cluster_keywords_weights,\n",
    "    etiquetas_predichas,\n",
    "    documentos_preprocesados,\n",
    "    documentos_originales,\n",
    "    modelo_w2v,\n",
    "    num_documentos=5\n",
    "):\n",
    "    documentos_representativos = {}\n",
    "\n",
    "    for cluster_id, lista_palabras in cluster_keywords_weights.items():\n",
    "        documentos_representativos[cluster_id] = {}\n",
    "\n",
    "        for palabra, peso_real, peso_palabra in lista_palabras:\n",
    "            if palabra not in modelo_w2v.wv:\n",
    "                continue\n",
    "\n",
    "            vector_objetivo = modelo_w2v.wv[palabra]\n",
    "            docs_similares = []\n",
    "\n",
    "            for i, (etiqueta, doc) in enumerate(zip(etiquetas_predichas, documentos_preprocesados)):\n",
    "                if etiqueta != cluster_id:\n",
    "                    continue\n",
    "\n",
    "                vectores_doc = [modelo_w2v.wv[p] for p in doc if p in modelo_w2v.wv]\n",
    "                if not vectores_doc:\n",
    "                    continue\n",
    "\n",
    "                vector_promedio = np.mean(vectores_doc, axis=0)\n",
    "                similitud = np.dot(vector_promedio, vector_objetivo) / (\n",
    "                    norm(vector_promedio) * norm(vector_objetivo)\n",
    "                )\n",
    "\n",
    "                doc_resumen = documentos_originales[i][:100] + \"...\"\n",
    "                docs_similares.append((doc_resumen, similitud))\n",
    "\n",
    "            # Ordenar y limitar a los documentos más similares\n",
    "            docs_similares = sorted(docs_similares, key=lambda x: x[1], reverse=True)[:num_documentos]\n",
    "\n",
    "            # Normalizar similitudes para que sumen 1 y repartir el peso_palabra\n",
    "            suma_similitudes = sum(sim for _, sim in docs_similares)\n",
    "            if suma_similitudes > 0:\n",
    "                docs_ponderados = [\n",
    "                    (doc, sim,(sim / suma_similitudes) * peso_palabra)\n",
    "                    for doc, sim in docs_similares\n",
    "                ]\n",
    "                documentos_representativos[cluster_id][palabra] = docs_ponderados\n",
    "\n",
    "    return documentos_representativos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819a9ff1",
   "metadata": {},
   "source": [
    "## Función que genera Treemap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01f93d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportar_treemap_clusters_palabras_documentos_go_tooltip(\n",
    "    cluster_sizes,\n",
    "    cluster_keywords_weights,\n",
    "    documentos_representativos,\n",
    "    output_filename=\"treemap_clusters_palabras_documentos.html\",\n",
    "    nombres_clusters=None  # Nuevo parámetro opcional\n",
    "):\n",
    "    labels = []\n",
    "    parents = []\n",
    "    values = []\n",
    "    hover_texts = []\n",
    "\n",
    "    for cluster_id, size in cluster_sizes.items():\n",
    "        # Usar nombre representativo si está disponible, si no, usar \"Cluster {id}\"\n",
    "        cluster_name = nombres_clusters.get(cluster_id, f\"Cluster {cluster_id}\") if nombres_clusters else f\"Cluster {cluster_id}\"\n",
    "        \n",
    "        labels.append(cluster_name)\n",
    "        parents.append(\"\")\n",
    "        values.append(size)\n",
    "        hover_texts.append(f\"{cluster_name}<br>Tamaño: {size}\")\n",
    "\n",
    "        # Palabras clave dentro del clúster\n",
    "        for palabra, peso_real, peso_normalizado in cluster_keywords_weights[cluster_id]:\n",
    "            palabra_id = f\"{palabra} ({cluster_name})\"\n",
    "            labels.append(palabra_id)\n",
    "            parents.append(cluster_name)\n",
    "            values.append(peso_normalizado)\n",
    "            hover_texts.append(f\"Palabra: {palabra}<br>Relevancia: {peso_real:.2f}\")\n",
    "\n",
    "            # Documentos representativos de esa palabra\n",
    "            if cluster_id in documentos_representativos and palabra in documentos_representativos[cluster_id]:\n",
    "                for doc, peso_real_doc, peso_norm_doc in documentos_representativos[cluster_id][palabra]:\n",
    "                    doc_id = f\"{doc} ({palabra})\"\n",
    "                    labels.append(doc_id)\n",
    "                    parents.append(palabra_id)\n",
    "                    values.append(peso_norm_doc)\n",
    "                    hover_texts.append(f\"<b>Texto:</b><br>{doc}\"\n",
    "                                      f\"<b>Relevancia:</b> {peso_real_doc:.3f}\")\n",
    "\n",
    "    fig = go.Figure(go.Treemap(\n",
    "        labels=labels,\n",
    "        parents=parents,\n",
    "        values=values,\n",
    "        branchvalues=\"remainder\",\n",
    "        hovertext=hover_texts,\n",
    "        hoverinfo=\"text\"\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(title_text=\"Modelo de tópicos\", title_x=0.5)\n",
    "    fig.write_html(output_filename)\n",
    "    print(f\"Treemap exportado como {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbdbedf",
   "metadata": {},
   "source": [
    "Funciones para reordenar los clústeres generados por su tamaño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b92bddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reasignar_clusters_por_tamaño(cluster_sizes_ordenado, cluster_keywords_weights):\n",
    "    # Paso 1: Crear el nuevo mapeo de etiquetas antiguas a nuevas, en orden decreciente de tamaño\n",
    "    claves_ordenadas = list(cluster_sizes_ordenado.keys())\n",
    "    mapeo_clusters = {clave_antigua: nueva_id for nueva_id, clave_antigua in enumerate(claves_ordenadas)}\n",
    "    \n",
    "    # Paso 2: Aplicar el mapeo a cluster_keywords_weights\n",
    "    nuevo_cluster_keywords_weights = {\n",
    "        mapeo_clusters[cluster_id]: palabras\n",
    "        for cluster_id, palabras in cluster_keywords_weights.items()\n",
    "        if cluster_id in mapeo_clusters\n",
    "    }\n",
    "    \n",
    "    return nuevo_cluster_keywords_weights, mapeo_clusters\n",
    "\n",
    "def reasignar_documentos_representativos(documentos_representativos, mapeo_clusters):\n",
    "    \"\"\"\n",
    "    Reasigna los IDs de cluster en el diccionario de documentos representativos\n",
    "    usando el mapeo de IDs antiguos a nuevos.\n",
    "    \n",
    "    Args:\n",
    "        documentos_representativos (dict): Diccionario con claves de cluster originales.\n",
    "        mapeo_clusters (dict): Diccionario que mapea ID antiguo → ID nuevo.\n",
    "\n",
    "    Returns:\n",
    "        dict: Nuevo diccionario con las claves reasignadas.\n",
    "    \"\"\"\n",
    "    nuevos_documentos = {\n",
    "        mapeo_clusters[cluster_id]: contenido\n",
    "        for cluster_id, contenido in documentos_representativos.items()\n",
    "        if cluster_id in mapeo_clusters\n",
    "    }\n",
    "    return nuevos_documentos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec2b17e",
   "metadata": {},
   "source": [
    "Generamos las palabras para cada clúster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b3ec18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_keywords_weights = obtener_palabras_representativas_w2v2_con_pesos_normalizados(\n",
    "    model_w2v=modelo_w2v_cargado,\n",
    "    documents=documents,\n",
    "    labels=np.array(etiquetas_meta_documentos),\n",
    "    n=10\n",
    "  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69d4d3a",
   "metadata": {},
   "source": [
    "Generamos los documentos representativos por palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "307c67ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "documentos_representativos = construir_documentos_representativos_para_treemap_ponderado(\n",
    "    cluster_keywords_weights,\n",
    "    etiquetas_meta_documentos,\n",
    "    documents,\n",
    "    documentos_originales,\n",
    "    modelo_w2v=modelo_w2v_cargado\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef59d57b",
   "metadata": {},
   "source": [
    "La visualización requiere que los clústers estén ordenados del 0..n por orden de tamaño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb3f371d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevo_cluster_keywords_weights, mapeo_clusters = reasignar_clusters_por_tamaño(\n",
    "    cluster_sizes_dict, cluster_keywords_weights\n",
    ")\n",
    "nuevos_documentos_representativos = reasignar_documentos_representativos(\n",
    "    documentos_representativos, mapeo_clusters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3e5272",
   "metadata": {},
   "source": [
    "Definimos las variables que utilizamos para generar el treemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74bbd61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treemap exportado como recursos/treemap_temas.html\n"
     ]
    }
   ],
   "source": [
    "cluster_sizes_ordenado = {i: valor for i, (_, valor) in enumerate(list(cluster_sizes_dict.items())[:13])}\n",
    "cluster_sizes = cluster_sizes_ordenado\n",
    "cluster_keywords_weights=nuevo_cluster_keywords_weights\n",
    "documentos_representativos=nuevos_documentos_representativos\n",
    "nombres_clusters = {\n",
    "    0: \"Varios tipos Incidencias vía pública\",\n",
    "    1: \"Estado de la vía pública \",\n",
    "    2: \"Limpieza\",\n",
    "    3: \"Tráfico\",\n",
    "    4: \"Trámites y servicios\",\n",
    "    5: \"Juegos infantiles\",\n",
    "    6: \"Transporte público\",\n",
    "    7: \"Parques y jardines\",\n",
    "    8: \"Instalaciones municipales\",\n",
    "    9: \"Urbanismo\"\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "exportar_treemap_clusters_palabras_documentos_go_tooltip(\n",
    "    cluster_sizes,\n",
    "    cluster_keywords_weights,\n",
    "    documentos_representativos,\n",
    "    output_filename=\"recursos/treemap_temas.html\",\n",
    "    nombres_clusters=nombres_clusters\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
