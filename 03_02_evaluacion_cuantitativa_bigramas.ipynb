{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31fdd79b-6338-454c-8203-e7f5b8cb7ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from gensim.models import LdaModel\n",
    "import ast\n",
    "from gsdmm import MovieGroupProcess\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import KMeans,AgglomerativeClustering\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, v_measure_score, confusion_matrix, rand_score, fowlkes_mallows_score, davies_bouldin_score, calinski_harabasz_score, silhouette_score\n",
    "from collections import Counter,defaultdict\n",
    "from bcubed_metrics.bcubed import Bcubed\n",
    "from gensim import models\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5d30e1",
   "metadata": {},
   "source": [
    "## Funciones para tratar datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3a3928b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_documents_for_dictionary(tokenized_documents, filtered_words):\n",
    "    filtered_documents = []\n",
    "    for doc in tokenized_documents:\n",
    "        filtered_doc = [word for word in doc if word in filtered_words]\n",
    "        filtered_documents.append(filtered_doc)\n",
    "    return filtered_documents\n",
    "\n",
    "def guardar_objeto(resultados, nombre_archivo):\n",
    "    with open(nombre_archivo, \"wb\") as archivo:\n",
    "        pickle.dump(resultados, archivo)\n",
    "        \n",
    "# matriz donde cada fila representa un vector de documento, obtenido como el promedio de los vectores de las palabras que lo componen\n",
    "def get_document_vectors(model, documents):\n",
    "    document_vectors = []\n",
    "    for doc in documents:\n",
    "        word_vectors = [model.wv[word] for word in doc if word in model.wv.key_to_index]\n",
    "        if word_vectors:\n",
    "            document_vector = np.mean(word_vectors, axis=0)\n",
    "            document_vectors.append(document_vector)\n",
    "        else:\n",
    "            # Manejar documentos vacíos o sin palabras válidas\n",
    "            # Omitir el documento o asignar un vector de ceros\n",
    "            document_vectors.append(np.zeros(model.vector_size)) #vector de ceros\n",
    "            pass #omitir el documento\n",
    "    return document_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d1e0df",
   "metadata": {},
   "source": [
    "## Funciones para evaluar modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ddcb479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bcubed_predicted_clustering(labels, true_labels):\n",
    "    cluster_to_service_counts = defaultdict(lambda: defaultdict(int))\n",
    "    for i, cluster in enumerate(labels):\n",
    "        service = true_labels[i]\n",
    "        cluster_to_service_counts[cluster][service] += 1\n",
    "    predicted_clustering = []\n",
    "    for cluster, service_counts in cluster_to_service_counts.items():\n",
    "        predicted_clustering.append(dict(service_counts))\n",
    "    return predicted_clustering\n",
    "\n",
    "\n",
    "def convertir_claves_a_string_en_predicted_clustering(predicted_clustering):\n",
    "    nuevo_predicted_clustering = []\n",
    "    for topic_counts in predicted_clustering:\n",
    "        nuevo_topic_counts = convertir_claves_a_string(topic_counts)\n",
    "        nuevo_predicted_clustering.append(nuevo_topic_counts)\n",
    "    return nuevo_predicted_clustering\n",
    "\n",
    "\n",
    "def contar_codigos_servicio(true_labels):\n",
    "    conteo_servicios = {}\n",
    "    for servicio in true_labels:\n",
    "        if servicio in conteo_servicios:\n",
    "            conteo_servicios[servicio] += 1\n",
    "        else:\n",
    "            conteo_servicios[servicio] = 1\n",
    "    return conteo_servicios\n",
    "\n",
    "def convertir_claves_a_string(diccionario):\n",
    "    nuevo_diccionario = {}\n",
    "    for clave, valor in diccionario.items():\n",
    "        nueva_clave = str(clave)  # Convierte la clave a string\n",
    "        nuevo_diccionario[nueva_clave] = valor\n",
    "    return nuevo_diccionario\n",
    "\n",
    "\n",
    "def evaluar_modelo(etiquetas_reales, etiquetas_predichas, X=None):\n",
    "    \n",
    "    resultados = {}\n",
    "\n",
    "    resultados[\"adjusted_rand_score\"] = adjusted_rand_score(\n",
    "        etiquetas_reales, etiquetas_predichas\n",
    "    )\n",
    "    resultados[\"normalized_mutual_info_score\"] = normalized_mutual_info_score(\n",
    "        etiquetas_reales, etiquetas_predichas\n",
    "    )\n",
    "    \n",
    "    resultados[\"confusion_matrix\"] = confusion_matrix(\n",
    "        etiquetas_reales, etiquetas_predichas\n",
    "    )\n",
    "   \n",
    "    resultados[\"fowlkes_mallows_score\"] = fowlkes_mallows_score(\n",
    "        etiquetas_reales, etiquetas_predichas\n",
    "    )\n",
    "    \n",
    "    # Métricas B-Cubed\n",
    "    #Preparar diccionario para cluster indicar documentos asociados a etiquetas reales\n",
    "    \n",
    "    predicted_clustering = create_bcubed_predicted_clustering(etiquetas_predichas , etiquetas_reales)\n",
    "    predicted_clustering_string = convertir_claves_a_string_en_predicted_clustering(predicted_clustering)\n",
    "   \n",
    "    #Preparar diccionario con ground_truth_cluster\n",
    "    \n",
    "    conteo_servicios = contar_codigos_servicio(etiquetas_reales)\n",
    "    ground_labels = convertir_claves_a_string(conteo_servicios)\n",
    "   \n",
    "    b = Bcubed(ground_truth_clustering=ground_labels, predicted_clustering=predicted_clustering_string)\n",
    "   \n",
    "    resultados[\"bcubed_precision\"] = b.bcubed_precision\n",
    "    resultados[\"bcubed_recall\"] = b.bcubed_recall\n",
    "    resultados[\"bcubed_f1\"] = b.bcubed_f1\n",
    "    \n",
    "    # Métricas de validación interna\n",
    "    \n",
    "    if X is not None:\n",
    "        resultados[\"davies_bouldin_score\"] = davies_bouldin_score(\n",
    "          X, etiquetas_predichas\n",
    "      )\n",
    "        resultados[\"calinski_harabasz_score\"] = calinski_harabasz_score(\n",
    "          X, etiquetas_predichas\n",
    "      )\n",
    "        resultados[\"silhouette_score\"] = silhouette_score(\n",
    "          X, etiquetas_predichas\n",
    "      )\n",
    "        resultados[\"homogeneity_score\"] = homogeneity_score(\n",
    "        etiquetas_reales, etiquetas_predichas\n",
    "    )\n",
    "        resultados[\"completeness_score\"] = completeness_score(\n",
    "        etiquetas_reales, etiquetas_predichas\n",
    "    )\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3116858",
   "metadata": {},
   "source": [
    "## Función principal para generar y evaluar modelos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a78622fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_y_evaluar_modelos_topicos(etiquetas_reales, modelos=[\"lda-bi\", \"hlda\", \"gsdmm\", \"bertopic_Roberta\",\"bertopic\", \"agglomerative_word2vec\",\"agglomerative_tfidf\", \"kmeans_Tfidf\",\"kmeans_word2vec_100\",\"kmeans_word2vec_150\",\"kmeans_word2vec_200\",\"kmeans_word2vec_250\"], num_ejecuciones=5, **kwargs):\n",
    "    \n",
    "    for modelo_nombre in modelos:\n",
    "        resultados_bi[modelo_nombre] = {}\n",
    "        resultados_bi[modelo_nombre][\"etiquetas_predichas\"] = []  # Inicializa la lista de etiquetas predichas\n",
    "        resultados_ejecuciones = []\n",
    "        tiempos_entrenamiento = []\n",
    "        random_seeds = [42, 123, 567, 890, 1001]\n",
    "        modelo = None\n",
    "        X = None\n",
    "        if modelo_nombre == \"bertopic\" or modelo_nombre == \"bertopic_Roberta\": \n",
    "            for ejecucion in range(num_ejecuciones):\n",
    "                tiempo_inicio = time.time()\n",
    "                if modelo_nombre == \"bertopic\":\n",
    "                    documentos = kwargs.get(\"documentos\")\n",
    "                    #text_documents = [\" \".join(doc) for doc in documentos]\n",
    "                    vectorizador = TfidfVectorizer(ngram_range=(2, 2))\n",
    "                    bertopic_model = BERTopic(vectorizer_model=vectorizador,language=\"spanish\",nr_topics=len(set(etiquetas_reales)),verbose=True)\n",
    "                    etiquetas_predichas, _ = bertopic_model.fit_transform(documentos)\n",
    "                    # Obtenemos las representaciones vectoriales de BERTopic\n",
    "                    # embedding_model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "                    # X = embedding_model.encode(documentos)  \n",
    "                elif modelo_nombre == \"bertopic_Roberta\":\n",
    "                    documentos = kwargs.get(\"documentos\")\n",
    "                    #text_documents = [\" \".join(doc) for doc in documentos]\n",
    "                    # Cargar un modelo RoBERTa pre-entrenado\n",
    "                    embedding_model = SentenceTransformer(\"roberta-base-nli-stsb-mean-tokens\")\n",
    "                    bertopic_model = BERTopic(nr_topics=len(set(etiquetas_reales)),verbose=True,embedding_model=embedding_model)\n",
    "                    etiquetas_predichas, _ = bertopic_model.fit_transform(documentos)\n",
    "                tiempo_fin = time.time()\n",
    "                tiempos_entrenamiento.append(tiempo_fin - tiempo_inicio)\n",
    "                if 'bertopic_model' in locals(): \n",
    "                    modelo = bertopic_model\n",
    "                    nombre_archivo = os.path.join(ruta_guardado, f\"{modelo_nombre}_ejecucion_{ejecucion}.pkl\") # Cambia la extensión a .pkl\n",
    "                    with open(nombre_archivo, \"wb\") as archivo:\n",
    "                        pickle.dump(modelo, archivo)\n",
    "                    resultados_ejecuciones.append(evaluar_modelo(etiquetas_reales, etiquetas_predichas, X))\n",
    "                    resultados_bi[modelo_nombre][\"resultados_ejecuciones\"] = resultados_ejecuciones\n",
    "\n",
    "        if modelo_nombre == \"agglomerative_word2vec\":\n",
    "            documentos = kwargs.get(\"documentos\")\n",
    "            agg_model = AgglomerativeClustering(n_clusters=len(set(etiquetas_reales)), linkage='ward')\n",
    "            etiquetas_predichas = agg_model.fit_predict(documentos)\n",
    "        elif modelo_nombre == \"agglomerative_Tfidf\":\n",
    "            tiempo_inicio = time.time()\n",
    "            documentos = kwargs.get(\"documentos\")\n",
    "            vectorizer = TfidfVectorizer()\n",
    "            documentos_como_cadenas = [\" \".join(doc) for doc in documentos]\n",
    "            # Calcular TF-IDF\n",
    "            tfidf_matrix = vectorizer.fit_transform(documentos_como_cadenas)\n",
    "            tfidf_matrix_dense = tfidf_matrix.toarray()\n",
    "            agg_model = AgglomerativeClustering(n_clusters=len(set(etiquetas_reales)), linkage='ward')\n",
    "            etiquetas_predichas = agg_model.fit_predict(tfidf_matrix_dense)\n",
    "            tiempo_fin = time.time()\n",
    "            tiempos_entrenamiento.append(tiempo_fin - tiempo_inicio)\n",
    "        if 'agg_model' in locals(): \n",
    "            modelo = agg_model\n",
    "            nombre_archivo = os.path.join(ruta_guardado, f\"{modelo_nombre}_ejecucion_0.pkl\") # Cambia la extensión a .pkl\n",
    "            with open(nombre_archivo, \"wb\") as archivo:\n",
    "                pickle.dump(modelo, archivo)\n",
    "                    \n",
    "            resultados_bi[modelo_nombre][\"etiquetas_predichas\"].append(etiquetas_predichas)\n",
    "            resultados_ejecuciones.append(evaluar_modelo(etiquetas_reales, etiquetas_predichas, X))\n",
    "            resultados_bi[modelo_nombre][\"resultados_ejecuciones\"] = resultados_ejecuciones\n",
    "            \n",
    "        for seed in random_seeds:\n",
    "            tiempo_inicio = time.time()\n",
    "           \n",
    "\n",
    "            if modelo_nombre == \"lda-bi\":\n",
    "                corpus = kwargs.get(\"corpus\")\n",
    "                diccionario = kwargs.get(\"diccionario\")\n",
    "                if corpus is None:\n",
    "                    raise ValueError(\"corpus debe proporcionarse para el modelo LDA.\")\n",
    "                if diccionario is None:\n",
    "                    raise ValueError(\"diccionario debe proporcionarse para el modelo GSDMM.\")                \n",
    "                lda_model = models.LdaModel(corpus, num_topics=len(set(etiquetas_reales)), id2word=diccionario, alpha=0.05, eta=0.01, iterations=100, random_state=seed  )\n",
    "                etiquetas_predichas = [max(lda_model[doc], key=lambda x: x[1])[0] for doc in corpus]\n",
    "                \n",
    "                \n",
    "                          \n",
    "                \n",
    "            elif modelo_nombre == \"gsdmm\":\n",
    "                n_terms = kwargs.get(\"n_terms\")\n",
    "                documentos = kwargs.get(\"documentos\")\n",
    "                if n_terms is None:\n",
    "                    raise ValueError(\"n_terms debe proporcionarse para el modelo GSDMM.\")\n",
    "                if documentos is None:\n",
    "                    raise ValueError(\"documentos debe proporcionarse para el modelo GSDMM.\")    \n",
    "                gsdmm_model = MovieGroupProcess(K=len(set(etiquetas_reales)), n_iters=30, alpha=0.1, beta=0.1)\n",
    "                y = gsdmm_model.fit(documentos,n_terms)\n",
    "                etiquetas_predichas = np.array(y)\n",
    "                \n",
    "         \n",
    "          \n",
    "                            \n",
    "            elif modelo_nombre == \"kmeans_Tfidf\":\n",
    "                documentos = kwargs.get(\"documentos\")\n",
    "                vectorizador = TfidfVectorizer(ngram_range=(2, 2))\n",
    "                documentos_como_cadenas = [\" \".join(doc) for doc in documentos]\n",
    "                # Calcular TF-IDF\n",
    "                tfidf_matrix = vectorizador.fit_transform(documentos_como_cadenas)\n",
    "                kmeans_model = KMeans(n_clusters=len(set(etiquetas_reales)), max_iter=100,random_state=seed )\n",
    "                etiquetas_predichas = kmeans_model.fit_predict(tfidf_matrix)\n",
    "            elif modelo_nombre == \"kmeans_word2vec\" or modelo_nombre == \"kmeans_word2vec_100\" or modelo_nombre == \"kmeans_word2vec_150\" or modelo_nombre == \"kmeans_word2vec_200\" or modelo_nombre == \"kmeans_word2vec_250\":\n",
    "                documentos = kwargs.get(\"documentos\")\n",
    "                kmeans_model = KMeans(n_clusters=len(set(etiquetas_reales)), max_iter=100, random_state=seed )\n",
    "                etiquetas_predichas = kmeans_model.fit_predict(documentos)                \n",
    "\n",
    "            tiempo_fin = time.time()\n",
    "            tiempos_entrenamiento.append(tiempo_fin - tiempo_inicio)\n",
    "            \n",
    "        # Guardar el modelo\n",
    "            if 'lda_model' in locals(): modelo = lda_model\n",
    "            elif 'hlda_model' in locals(): modelo = hlda_model\n",
    "            elif 'gsdmm_model' in locals(): modelo = gsdmm_model\n",
    "            elif 'kmeans_model' in locals(): modelo = kmeans_model\n",
    "                 \n",
    "            # Guardar el modelo\n",
    "            if modelo is not None:\n",
    "                nombre_archivo = os.path.join(ruta_guardado, f\"{modelo_nombre}_ejecucion_{seed}.pkl\") # Cambia la extensión a .pkl\n",
    "                with open(nombre_archivo, \"wb\") as archivo:\n",
    "                    pickle.dump(modelo, archivo)\n",
    "                    \n",
    "            resultados_bi[modelo_nombre][\"etiquetas_predichas\"].append(etiquetas_predichas)\n",
    "                \n",
    "            resultados_ejecuciones.append(evaluar_modelo(etiquetas_reales, etiquetas_predichas, X))\n",
    "            resultados_bi[modelo_nombre][\"resultados_ejecuciones\"] = resultados_ejecuciones\n",
    "            \n",
    "    # Promediar y calcular la desviación estándar de los resultados\n",
    "        for metrica in resultados_ejecuciones[0]:\n",
    "            valores_metrica = [resultado[metrica] for resultado in resultados_ejecuciones]\n",
    "            resultados_bi[modelo_nombre][metrica] = {\n",
    "                \"promedio\": np.mean(valores_metrica),\n",
    "                \"desviacion_estandar\": np.std(valores_metrica)\n",
    "            }\n",
    "\n",
    "        resultados_bi[modelo_nombre][\"tiempo_entrenamiento\"] = {\n",
    "            \"promedio\": np.mean(tiempos_entrenamiento),\n",
    "            \"desviacion_estandar\": np.std(tiempos_entrenamiento)\n",
    "        }\n",
    "    guardar_objeto(resultados_bi, \"resultados_modelos_bi.pkl\")   \n",
    "    return resultados_bi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f669ce4a",
   "metadata": {},
   "source": [
    "### Función para visualizar resultados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a995a7e1-ccd2-4c2e-b79c-d94f4e725bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_tabla_metricas_fijas2(metricas, metricas_deseadas, modelos_deseados=None):\n",
    "    tabla_html = \"<table>\\n\"\n",
    "    tabla_html += \"  <tr>\\n\"\n",
    "    tabla_html += \"    <th>Métrica</th>\\n\"\n",
    "\n",
    "    # Determinar qué modelos mostrar\n",
    "    modelos_a_mostrar = modelos_deseados if modelos_deseados else list(metricas.keys())\n",
    "\n",
    "    for modelo in modelos_a_mostrar:\n",
    "        tabla_html += f\"    <th>{modelo.upper()}</th>\\n\"\n",
    "    tabla_html += \"  </tr>\\n\"\n",
    "\n",
    "    for metrica in metricas_deseadas:\n",
    "        tabla_html += \"  <tr>\\n\"\n",
    "        tabla_html += f\"    <td>{metrica.replace('_', ' ').title()}</td>\\n\"\n",
    "        for modelo in modelos_a_mostrar:\n",
    "            if metrica in metricas[modelo]:\n",
    "                promedio = metricas[modelo][metrica]['promedio']\n",
    "                desviacion = metricas[modelo][metrica]['desviacion_estandar']\n",
    "                tabla_html += f\"    <td>{promedio:.4f} ± {desviacion:.4f}</td>\\n\"\n",
    "            else:\n",
    "                tabla_html += \"    <td>-</td>\\n\"  # Si la métrica no está para un modelo\n",
    "        tabla_html += \"  </tr>\\n\"\n",
    "\n",
    "    tabla_html += \"</table>\"\n",
    "    return tabla_html\n",
    "\n",
    "# Ejemplo de uso con modelos específicos:\n",
    "metricas_deseadas = [\n",
    "    'adjusted_rand_score',\n",
    "    'normalized_mutual_info_score',\n",
    "    'fowlkes_mallows_score',\n",
    "    'bcubed_precision',\n",
    "    'bcubed_recall',\n",
    "    'bcubed_f1',\n",
    "    'tiempo_entrenamiento'\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a18befd",
   "metadata": {},
   "source": [
    "# carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "493ec84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargar datos, diccionario y corpus preparados en preprocesado \n",
    "\n",
    "df_preprocesado = pd.read_csv('df_preprocesado.csv', sep=';')\n",
    "dictionary = Dictionary.load('dictionary_filtrado_bi.gensim')\n",
    "corpus = MmCorpus('corpus_bi.mm')\n",
    "\n",
    "\n",
    "#Cargar etiquetas de servicios asociados a documentos\n",
    "\n",
    "true_labels = df_preprocesado['code_service_unificado'].tolist()\n",
    "\n",
    "#Iniciarlizar resultados y documentos\n",
    "\n",
    "documentos=[]\n",
    "resultados_bi = {}\n",
    "\n",
    "#Preparar ruta para guardado\n",
    "\n",
    "ruta_guardado = \"./modelos_topicos_bi\"\n",
    "if not os.path.exists(ruta_guardado):\n",
    "    os.makedirs(ruta_guardado)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "042ed784",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparar documentos para partir de las mismas condiciones \n",
    "filtered_words = set(dictionary.token2id.keys())\n",
    "n_term=len(filtered_words)\n",
    "preprocesado_documents=df_preprocesado['bigramas_preprocesado'].apply(ast.literal_eval)    \n",
    "documents = filter_documents_for_dictionary(preprocesado_documents, filtered_words)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c9eb31",
   "metadata": {},
   "source": [
    "## Generar y evaluar modelos "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67044280",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eca37d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_bi = generar_y_evaluar_modelos_topicos(true_labels, modelos=[\"lda-bi\"],diccionario=dictionary, corpus=corpus)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23891b1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelos_a_mostrar = ['lda-bi'] # Solo muestra estos modelos.\n",
    "\n",
    "tabla_html = generar_tabla_metricas_fijas2(resultados_bi, metricas_deseadas, modelos_a_mostrar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1613adf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "  <tr>\n",
       "    <th>Métrica</th>\n",
       "    <th>LDA-BI</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Adjusted Rand Score</td>\n",
       "    <td>0.0473 ± 0.0066</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Normalized Mutual Info Score</td>\n",
       "    <td>0.1181 ± 0.0025</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Fowlkes Mallows Score</td>\n",
       "    <td>0.1025 ± 0.0084</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Bcubed Precision</td>\n",
       "    <td>0.1762 ± 0.0036</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Bcubed Recall</td>\n",
       "    <td>0.0673 ± 0.0056</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Bcubed F1</td>\n",
       "    <td>0.0766 ± 0.0053</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Tiempo Entrenamiento</td>\n",
       "    <td>19.8727 ± 0.4344</td>\n",
       "  </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(tabla_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fb1d89",
   "metadata": {},
   "source": [
    "### GSDMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e08254ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resultados_modelos.pkl', 'rb') as archivo:\n",
    "    resultados = pickle.load(archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b079f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In stage 0: transferred 60690 clusters with 61 clusters populated\n",
      "In stage 1: transferred 38670 clusters with 61 clusters populated\n",
      "In stage 2: transferred 21536 clusters with 61 clusters populated\n",
      "In stage 3: transferred 14021 clusters with 61 clusters populated\n",
      "In stage 4: transferred 10702 clusters with 61 clusters populated\n",
      "In stage 5: transferred 9327 clusters with 61 clusters populated\n",
      "In stage 6: transferred 8624 clusters with 61 clusters populated\n",
      "In stage 7: transferred 8194 clusters with 61 clusters populated\n",
      "In stage 8: transferred 8004 clusters with 61 clusters populated\n",
      "In stage 9: transferred 7563 clusters with 61 clusters populated\n",
      "In stage 10: transferred 7179 clusters with 61 clusters populated\n",
      "In stage 11: transferred 7081 clusters with 61 clusters populated\n",
      "In stage 12: transferred 6828 clusters with 61 clusters populated\n",
      "In stage 13: transferred 6736 clusters with 61 clusters populated\n",
      "In stage 14: transferred 6538 clusters with 61 clusters populated\n",
      "In stage 15: transferred 6398 clusters with 61 clusters populated\n",
      "In stage 16: transferred 6383 clusters with 61 clusters populated\n",
      "In stage 17: transferred 6339 clusters with 61 clusters populated\n",
      "In stage 18: transferred 6306 clusters with 61 clusters populated\n",
      "In stage 19: transferred 6337 clusters with 61 clusters populated\n",
      "In stage 20: transferred 6364 clusters with 61 clusters populated\n",
      "In stage 21: transferred 6160 clusters with 61 clusters populated\n",
      "In stage 22: transferred 6253 clusters with 61 clusters populated\n",
      "In stage 23: transferred 6251 clusters with 61 clusters populated\n",
      "In stage 24: transferred 6309 clusters with 61 clusters populated\n",
      "In stage 25: transferred 6288 clusters with 61 clusters populated\n",
      "In stage 26: transferred 6279 clusters with 61 clusters populated\n",
      "In stage 27: transferred 6236 clusters with 61 clusters populated\n",
      "In stage 28: transferred 6232 clusters with 61 clusters populated\n",
      "In stage 29: transferred 6189 clusters with 61 clusters populated\n",
      "In stage 0: transferred 60798 clusters with 61 clusters populated\n",
      "In stage 1: transferred 37331 clusters with 61 clusters populated\n",
      "In stage 2: transferred 21617 clusters with 61 clusters populated\n",
      "In stage 3: transferred 14813 clusters with 61 clusters populated\n",
      "In stage 4: transferred 11564 clusters with 61 clusters populated\n",
      "In stage 5: transferred 9792 clusters with 61 clusters populated\n",
      "In stage 6: transferred 8572 clusters with 61 clusters populated\n",
      "In stage 7: transferred 7993 clusters with 61 clusters populated\n",
      "In stage 8: transferred 7690 clusters with 61 clusters populated\n",
      "In stage 9: transferred 7355 clusters with 61 clusters populated\n",
      "In stage 10: transferred 7223 clusters with 61 clusters populated\n",
      "In stage 11: transferred 7097 clusters with 61 clusters populated\n",
      "In stage 12: transferred 7101 clusters with 61 clusters populated\n",
      "In stage 13: transferred 7116 clusters with 61 clusters populated\n",
      "In stage 14: transferred 6957 clusters with 61 clusters populated\n",
      "In stage 15: transferred 7043 clusters with 61 clusters populated\n",
      "In stage 16: transferred 6950 clusters with 61 clusters populated\n",
      "In stage 17: transferred 6851 clusters with 61 clusters populated\n",
      "In stage 18: transferred 6849 clusters with 61 clusters populated\n",
      "In stage 19: transferred 6711 clusters with 61 clusters populated\n",
      "In stage 20: transferred 6743 clusters with 61 clusters populated\n",
      "In stage 21: transferred 6661 clusters with 61 clusters populated\n",
      "In stage 22: transferred 6660 clusters with 61 clusters populated\n",
      "In stage 23: transferred 6525 clusters with 61 clusters populated\n",
      "In stage 24: transferred 6424 clusters with 61 clusters populated\n",
      "In stage 25: transferred 6533 clusters with 61 clusters populated\n",
      "In stage 26: transferred 6504 clusters with 61 clusters populated\n",
      "In stage 27: transferred 6371 clusters with 61 clusters populated\n",
      "In stage 28: transferred 6423 clusters with 61 clusters populated\n",
      "In stage 29: transferred 6433 clusters with 61 clusters populated\n",
      "In stage 0: transferred 60805 clusters with 61 clusters populated\n",
      "In stage 1: transferred 38548 clusters with 61 clusters populated\n",
      "In stage 2: transferred 21536 clusters with 61 clusters populated\n",
      "In stage 3: transferred 14489 clusters with 61 clusters populated\n",
      "In stage 4: transferred 11290 clusters with 61 clusters populated\n",
      "In stage 5: transferred 9782 clusters with 61 clusters populated\n",
      "In stage 6: transferred 8930 clusters with 61 clusters populated\n",
      "In stage 7: transferred 8254 clusters with 61 clusters populated\n",
      "In stage 8: transferred 7844 clusters with 61 clusters populated\n",
      "In stage 9: transferred 7432 clusters with 61 clusters populated\n",
      "In stage 10: transferred 7227 clusters with 61 clusters populated\n",
      "In stage 11: transferred 7289 clusters with 61 clusters populated\n",
      "In stage 12: transferred 7074 clusters with 61 clusters populated\n",
      "In stage 13: transferred 6928 clusters with 61 clusters populated\n",
      "In stage 14: transferred 6742 clusters with 61 clusters populated\n",
      "In stage 15: transferred 6655 clusters with 61 clusters populated\n",
      "In stage 16: transferred 6623 clusters with 61 clusters populated\n",
      "In stage 17: transferred 6682 clusters with 61 clusters populated\n",
      "In stage 18: transferred 6553 clusters with 61 clusters populated\n",
      "In stage 19: transferred 6552 clusters with 61 clusters populated\n",
      "In stage 20: transferred 6454 clusters with 61 clusters populated\n",
      "In stage 21: transferred 6451 clusters with 61 clusters populated\n",
      "In stage 22: transferred 6365 clusters with 61 clusters populated\n",
      "In stage 23: transferred 6341 clusters with 61 clusters populated\n",
      "In stage 24: transferred 6277 clusters with 61 clusters populated\n",
      "In stage 25: transferred 6271 clusters with 61 clusters populated\n",
      "In stage 26: transferred 6318 clusters with 61 clusters populated\n",
      "In stage 27: transferred 6289 clusters with 61 clusters populated\n",
      "In stage 28: transferred 6222 clusters with 61 clusters populated\n",
      "In stage 29: transferred 6302 clusters with 61 clusters populated\n",
      "In stage 0: transferred 60740 clusters with 61 clusters populated\n",
      "In stage 1: transferred 38792 clusters with 61 clusters populated\n",
      "In stage 2: transferred 23071 clusters with 61 clusters populated\n",
      "In stage 3: transferred 15005 clusters with 61 clusters populated\n",
      "In stage 4: transferred 11547 clusters with 61 clusters populated\n",
      "In stage 5: transferred 9739 clusters with 61 clusters populated\n",
      "In stage 6: transferred 8801 clusters with 61 clusters populated\n",
      "In stage 7: transferred 8153 clusters with 61 clusters populated\n",
      "In stage 8: transferred 7787 clusters with 61 clusters populated\n",
      "In stage 9: transferred 7581 clusters with 61 clusters populated\n",
      "In stage 10: transferred 7361 clusters with 61 clusters populated\n",
      "In stage 11: transferred 7237 clusters with 61 clusters populated\n",
      "In stage 12: transferred 7093 clusters with 61 clusters populated\n",
      "In stage 13: transferred 7085 clusters with 61 clusters populated\n",
      "In stage 14: transferred 6938 clusters with 61 clusters populated\n",
      "In stage 15: transferred 6818 clusters with 61 clusters populated\n",
      "In stage 16: transferred 6793 clusters with 61 clusters populated\n",
      "In stage 17: transferred 6857 clusters with 61 clusters populated\n",
      "In stage 18: transferred 6769 clusters with 61 clusters populated\n",
      "In stage 19: transferred 6738 clusters with 61 clusters populated\n",
      "In stage 20: transferred 6783 clusters with 61 clusters populated\n",
      "In stage 21: transferred 6647 clusters with 61 clusters populated\n",
      "In stage 22: transferred 6635 clusters with 61 clusters populated\n",
      "In stage 23: transferred 6650 clusters with 61 clusters populated\n",
      "In stage 24: transferred 6495 clusters with 61 clusters populated\n",
      "In stage 25: transferred 6532 clusters with 61 clusters populated\n",
      "In stage 26: transferred 6532 clusters with 61 clusters populated\n",
      "In stage 27: transferred 6576 clusters with 61 clusters populated\n",
      "In stage 28: transferred 6596 clusters with 61 clusters populated\n",
      "In stage 29: transferred 6546 clusters with 61 clusters populated\n",
      "In stage 0: transferred 60757 clusters with 61 clusters populated\n",
      "In stage 1: transferred 39051 clusters with 61 clusters populated\n",
      "In stage 2: transferred 21797 clusters with 61 clusters populated\n",
      "In stage 3: transferred 13882 clusters with 61 clusters populated\n",
      "In stage 4: transferred 10710 clusters with 61 clusters populated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In stage 5: transferred 9045 clusters with 61 clusters populated\n",
      "In stage 6: transferred 8287 clusters with 61 clusters populated\n",
      "In stage 7: transferred 7689 clusters with 61 clusters populated\n",
      "In stage 8: transferred 7382 clusters with 61 clusters populated\n",
      "In stage 9: transferred 7186 clusters with 61 clusters populated\n",
      "In stage 10: transferred 7002 clusters with 61 clusters populated\n",
      "In stage 11: transferred 6731 clusters with 61 clusters populated\n",
      "In stage 12: transferred 6687 clusters with 61 clusters populated\n",
      "In stage 13: transferred 6614 clusters with 61 clusters populated\n",
      "In stage 14: transferred 6623 clusters with 61 clusters populated\n",
      "In stage 15: transferred 6539 clusters with 61 clusters populated\n",
      "In stage 16: transferred 6470 clusters with 61 clusters populated\n",
      "In stage 17: transferred 6490 clusters with 61 clusters populated\n",
      "In stage 18: transferred 6374 clusters with 61 clusters populated\n",
      "In stage 19: transferred 6385 clusters with 61 clusters populated\n",
      "In stage 20: transferred 6404 clusters with 61 clusters populated\n",
      "In stage 21: transferred 6330 clusters with 61 clusters populated\n",
      "In stage 22: transferred 6282 clusters with 61 clusters populated\n",
      "In stage 23: transferred 6206 clusters with 61 clusters populated\n",
      "In stage 24: transferred 6194 clusters with 61 clusters populated\n",
      "In stage 25: transferred 6242 clusters with 61 clusters populated\n",
      "In stage 26: transferred 6231 clusters with 61 clusters populated\n",
      "In stage 27: transferred 6221 clusters with 61 clusters populated\n",
      "In stage 28: transferred 6236 clusters with 61 clusters populated\n",
      "In stage 29: transferred 6154 clusters with 61 clusters populated\n"
     ]
    }
   ],
   "source": [
    "resultados = generar_y_evaluar_modelos_topicos(true_labels, modelos=[\"gsdmm\"],n_terms=n_term,documentos=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf198d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "  <tr>\n",
       "    <th>Métrica</th>\n",
       "    <th>GSDMM</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Adjusted Rand Score</td>\n",
       "    <td>0.1913 ± 0.0103</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Normalized Mutual Info Score</td>\n",
       "    <td>0.3507 ± 0.0034</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Fowlkes Mallows Score</td>\n",
       "    <td>0.2638 ± 0.0109</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Bcubed Precision</td>\n",
       "    <td>0.3857 ± 0.0046</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Bcubed Recall</td>\n",
       "    <td>0.2024 ± 0.0123</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Bcubed F1</td>\n",
       "    <td>0.2104 ± 0.0095</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Tiempo Entrenamiento</td>\n",
       "    <td>2017.8562 ± 18.9466</td>\n",
       "  </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelos_a_mostrar = ['gsdmm'] # Solo muestra estos modelos.\n",
    "tabla5_html = generar_tabla_metricas_fijas2(resultados, metricas_deseadas, modelos_a_mostrar)\n",
    "display(HTML(tabla5_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442b95f8",
   "metadata": {},
   "source": [
    "### BERTOPIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8327194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resultados_modelos.pkl', 'rb') as archivo:\n",
    "    resultados = pickle.load(archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "556ffb88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Equipo Flip-Flap Me dirijo a ustedes aprovecha...\n",
       "1        Instalación deportiva para gimnasia deportiva ...\n",
       "2        Duda Permisos Hola, escribo en nombre de un gr...\n",
       "3        Noches Jueves viernes y sábado Cada vez es más...\n",
       "4        Falta de instalaciones deportivas Somos una fa...\n",
       "                               ...                        \n",
       "66450    Reposición o reparación de cubo de basura Buen...\n",
       "66451    Baldosas defectuosas Justo en la puerta de la ...\n",
       "66452    Aviso de que reclamación sigue sin respuesta  ...\n",
       "66453    Recogida de basura  Buenos dias, muestro mi ma...\n",
       "66454    Residencia xiort pontoneros- madre Rafols Buen...\n",
       "Name: texto, Length: 66455, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Si utilizamos documentos originales\n",
    "documents_original=df_preprocesado['texto']\n",
    "documents_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "faac4503",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 14:01:47,282 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c67aa78d33774ee9be7883006bf5738c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2077 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 14:15:10,990 - BERTopic - Embedding - Completed ✓\n",
      "2025-03-30 14:15:10,990 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-03-30 14:15:22,920 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-03-30 14:15:22,920 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-03-30 14:15:25,936 - BERTopic - Cluster - Completed ✓\n",
      "2025-03-30 14:15:25,952 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2025-03-30 14:15:32,978 - BERTopic - Representation - Completed ✓\n",
      "2025-03-30 14:15:32,993 - BERTopic - Topic reduction - Reducing number of topics\n",
      "2025-03-30 14:15:40,043 - BERTopic - Topic reduction - Reduced number of topics from 499 to 61\n",
      "C:\\Users\\Runob\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_index.py:143: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "2025-03-30 14:15:45,470 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8eb06ebeb634d78aed30c0de99c5812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2077 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 14:29:26,691 - BERTopic - Embedding - Completed ✓\n",
      "2025-03-30 14:29:26,691 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-03-30 14:29:38,610 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-03-30 14:29:38,610 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-03-30 14:29:41,432 - BERTopic - Cluster - Completed ✓\n",
      "2025-03-30 14:29:41,432 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2025-03-30 14:29:48,607 - BERTopic - Representation - Completed ✓\n",
      "2025-03-30 14:29:48,622 - BERTopic - Topic reduction - Reducing number of topics\n",
      "2025-03-30 14:29:55,999 - BERTopic - Topic reduction - Reduced number of topics from 490 to 61\n",
      "C:\\Users\\Runob\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_index.py:143: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "2025-03-30 14:30:01,313 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93361f6d4fb744869067d8798296c507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2077 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 14:43:51,480 - BERTopic - Embedding - Completed ✓\n",
      "2025-03-30 14:43:51,480 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-03-30 14:44:03,297 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-03-30 14:44:03,297 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-03-30 14:44:06,102 - BERTopic - Cluster - Completed ✓\n",
      "2025-03-30 14:44:06,102 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2025-03-30 14:44:13,480 - BERTopic - Representation - Completed ✓\n",
      "2025-03-30 14:44:13,496 - BERTopic - Topic reduction - Reducing number of topics\n",
      "2025-03-30 14:44:20,986 - BERTopic - Topic reduction - Reduced number of topics from 505 to 61\n",
      "C:\\Users\\Runob\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_index.py:143: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "2025-03-30 14:44:26,507 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa44e86e69b047b1b589e84a07075284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2077 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 14:58:04,185 - BERTopic - Embedding - Completed ✓\n",
      "2025-03-30 14:58:04,185 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-03-30 14:58:16,005 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-03-30 14:58:16,005 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-03-30 14:58:18,782 - BERTopic - Cluster - Completed ✓\n",
      "2025-03-30 14:58:18,782 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2025-03-30 14:58:30,895 - BERTopic - Representation - Completed ✓\n",
      "2025-03-30 14:58:30,907 - BERTopic - Topic reduction - Reducing number of topics\n",
      "2025-03-30 14:58:43,114 - BERTopic - Topic reduction - Reduced number of topics from 487 to 61\n",
      "C:\\Users\\Runob\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_index.py:143: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "2025-03-30 14:58:48,691 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7179b7ce10a44649bb157ffdf44a89a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2077 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 15:12:27,904 - BERTopic - Embedding - Completed ✓\n",
      "2025-03-30 15:12:27,904 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-03-30 15:12:39,880 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-03-30 15:12:39,880 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-03-30 15:12:42,688 - BERTopic - Cluster - Completed ✓\n",
      "2025-03-30 15:12:42,688 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2025-03-30 15:12:50,172 - BERTopic - Representation - Completed ✓\n",
      "2025-03-30 15:12:50,187 - BERTopic - Topic reduction - Reducing number of topics\n",
      "2025-03-30 15:12:57,687 - BERTopic - Topic reduction - Reduced number of topics from 525 to 61\n",
      "C:\\Users\\Runob\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_index.py:143: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "resultados = generar_y_evaluar_modelos_topicos(true_labels, modelos=[\"bertopic\"],documentos=documents_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11c644e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "  <tr>\n",
       "    <th>Métrica</th>\n",
       "    <th>BERTOPIC</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Adjusted Rand Score</td>\n",
       "    <td>0.0630 ± 0.0033</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Normalized Mutual Info Score</td>\n",
       "    <td>0.2867 ± 0.0049</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Fowlkes Mallows Score</td>\n",
       "    <td>0.2048 ± 0.0017</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Bcubed Precision</td>\n",
       "    <td>0.2646 ± 0.0110</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Bcubed Recall</td>\n",
       "    <td>0.3376 ± 0.0052</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Bcubed F1</td>\n",
       "    <td>0.1983 ± 0.0080</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Tiempo Entrenamiento</td>\n",
       "    <td>425.8352 ± 425.8867</td>\n",
       "  </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelos_a_mostrar = ['bertopic'] # Solo muestra estos modelos.\n",
    "\n",
    "tabla_html2 = generar_tabla_metricas_fijas2(resultados, metricas_deseadas, modelos_a_mostrar)\n",
    "display(HTML(tabla_html2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d85fb60",
   "metadata": {},
   "source": [
    "### Aglomerative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2eb03ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resultados_modelos_bi.pkl', 'rb') as archivo:\n",
    "    resultados_bi = pickle.load(archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22b8bef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_document_vectors.pkl', 'rb') as archivo:\n",
    "    all_document_vectors = pickle.load(archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb53182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = generar_y_evaluar_modelos_topicos(true_labels, modelos=[\"agglomerative_word2vec\"],documentos=all_document_vectors_bi[\"w2v_250_epochs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21d405dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = generar_y_evaluar_modelos_topicos(true_labels, modelos=[\"agglomerative_Tfidf\"],documentos=documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc4ba68",
   "metadata": {},
   "source": [
    "### Kmeans_word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca0ef23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resultados_modelos.pkl', 'rb') as archivo:\n",
    "    resultados = pickle.load(archivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99d54e5",
   "metadata": {},
   "source": [
    "#### Generar modelos partiendo de Word2Vec entre 100 y 250 epocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77365f36-957d-4959-8757-a7311668a813",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_to_test = [100, 150, 200, 250]  # Números de épocas a probar\n",
    "all_document_vectors_bi = {}  # Diccionario para almacenar los vectores de documentos\n",
    "\n",
    "for epochs in epochs_to_test:\n",
    "    model_name = f\"w2v_{epochs}_epochs\"\n",
    "    model = Word2Vec(\n",
    "        sentences=documents, vector_size=100, window=5, min_count=1, workers=4, seed=42\n",
    "    )\n",
    "    model.train(documents, total_examples=len(documents), epochs=epochs)\n",
    "    model.save(f\"w2v_{epochs}_epochs.model\") #guardamos el modelo.\n",
    "    document_vectors = get_document_vectors(model, documents)\n",
    "    document_vectors = [vector for vector in document_vectors if vector is not None]\n",
    "    document_vectors = np.array(document_vectors)\n",
    "    all_document_vectors_bi[model_name] = document_vectors  # Guardamos los vectores de documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cf3a50a-bbb8-47d3-98f9-ee598255996f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66455"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_document_vectors_bi[\"w2v_100_epochs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb1008bb-ca15-4cc0-a09b-33fa1f847cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_document_vectors_bi.pkl', \"wb\") as archivo:\n",
    "                    pickle.dump(all_document_vectors_bi, archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac6e6c39-0a33-4774-91c7-f483e99d295f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_word2vec={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7940905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_word2vec[\"kmeans_word2vec_100\"] = generar_y_evaluar_modelos_topicos(true_labels, modelos=[\"kmeans_word2vec_100\"],documentos=all_document_vectors_bi[\"w2v_100_epochs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f9177d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = generar_y_evaluar_modelos_topicos(true_labels, modelos=[\"kmeans_word2vec_150\"],documentos=all_document_vectors_bi[\"w2v_150_epochs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd0e5c57-15f1-44d6-9d08-d79adaa9de06",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = generar_y_evaluar_modelos_topicos(true_labels, modelos=[\"kmeans_word2vec_200\"],documentos=all_document_vectors_bi[\"w2v_200_epochs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04415b6f-4a3e-43f6-a761-da0121422e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = generar_y_evaluar_modelos_topicos(true_labels, modelos=[\"kmeans_word2vec_250\"],documentos=all_document_vectors_bi[\"w2v_250_epochs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2aabdbd5-b1a1-4826-8046-a897d0da13e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "  <tr>\n",
       "    <th>Métrica</th>\n",
       "    <th>KMEANS_WORD2VEC_100</th>\n",
       "    <th>KMEANS_WORD2VEC_150</th>\n",
       "    <th>KMEANS_WORD2VEC_200</th>\n",
       "    <th>KMEANS_WORD2VEC_250</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Adjusted Rand Score</td>\n",
       "    <td>0.1273 ± 0.0019</td>\n",
       "    <td>0.1247 ± 0.0035</td>\n",
       "    <td>0.1240 ± 0.0070</td>\n",
       "    <td>0.1239 ± 0.0032</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Normalized Mutual Info Score</td>\n",
       "    <td>0.3574 ± 0.0041</td>\n",
       "    <td>0.3626 ± 0.0023</td>\n",
       "    <td>0.3608 ± 0.0027</td>\n",
       "    <td>0.3637 ± 0.0045</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Fowlkes Mallows Score</td>\n",
       "    <td>0.1948 ± 0.0017</td>\n",
       "    <td>0.1922 ± 0.0035</td>\n",
       "    <td>0.1932 ± 0.0082</td>\n",
       "    <td>0.1927 ± 0.0025</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Bcubed Precision</td>\n",
       "    <td>0.4090 ± 0.0031</td>\n",
       "    <td>0.4138 ± 0.0034</td>\n",
       "    <td>0.4131 ± 0.0028</td>\n",
       "    <td>0.4146 ± 0.0032</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Bcubed Recall</td>\n",
       "    <td>0.1444 ± 0.0084</td>\n",
       "    <td>0.1443 ± 0.0074</td>\n",
       "    <td>0.1396 ± 0.0037</td>\n",
       "    <td>0.1415 ± 0.0039</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Bcubed F1</td>\n",
       "    <td>0.1688 ± 0.0041</td>\n",
       "    <td>0.1671 ± 0.0048</td>\n",
       "    <td>0.1663 ± 0.0053</td>\n",
       "    <td>0.1658 ± 0.0035</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Tiempo Entrenamiento</td>\n",
       "    <td>0.8057 ± 0.0283</td>\n",
       "    <td>0.6846 ± 0.0911</td>\n",
       "    <td>0.7843 ± 0.0628</td>\n",
       "    <td>0.8212 ± 0.0096</td>\n",
       "  </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "modelos_a_mostrar = ['kmeans_word2vec_100','kmeans_word2vec_150','kmeans_word2vec_200','kmeans_word2vec_250'] # Solo muestra estos modelos.\n",
    "\n",
    "tabla_html = generar_tabla_metricas_fijas2(resultados_bi, metricas_deseadas, modelos_a_mostrar)\n",
    "display(HTML(tabla_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f50b1d0-3c58-4801-b41b-550ec044de1c",
   "metadata": {},
   "source": [
    "### KMEANS tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09524d39-54d0-488c-8925-008ffc11550a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = generar_y_evaluar_modelos_topicos(true_labels, modelos=[\"kmeans_Tfidf\"],documentos=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63bbe354-4f22-42c3-afd3-bcc42b743f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos_a_mostrar = ['kmeans_Tfidf'] # Solo muestra estos modelos.\n",
    "\n",
    "tabla_html = generar_tabla_metricas_fijas2(resultados, metricas_deseadas, modelos_a_mostrar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26a828b0-5d02-4c77-8034-573cc551f427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "  <tr>\n",
       "    <th>Métrica</th>\n",
       "    <th>KMEANS_TFIDF</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Adjusted Rand Score</td>\n",
       "    <td>0.0212 ± 0.0090</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Normalized Mutual Info Score</td>\n",
       "    <td>0.2060 ± 0.0255</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Fowlkes Mallows Score</td>\n",
       "    <td>0.2483 ± 0.0716</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Bcubed Precision</td>\n",
       "    <td>0.2149 ± 0.0454</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Bcubed Recall</td>\n",
       "    <td>0.6654 ± 0.2527</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Bcubed F1</td>\n",
       "    <td>0.1821 ± 0.0306</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Tiempo Entrenamiento</td>\n",
       "    <td>23.6173 ± 6.8145</td>\n",
       "  </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(tabla_html))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
