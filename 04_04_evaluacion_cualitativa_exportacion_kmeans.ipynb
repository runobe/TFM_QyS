{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83b0508c",
   "metadata": {},
   "source": [
    "<h3> Palabras (TF-IDF)</h3>\n",
    "<ol><li>Obtener el vector del centroide: centroide = centroides[cluster_label]</li>\n",
    "<li>Obtener los índices de las n palabras con valores más altos en el centroide\n",
    "        palabras_representativas_indices = np.argsort(centroide)[::-1][:n]</li></ol>\n",
    "<h3>Documentos (TF-IDF) a nivel de clúster</h3>\n",
    "<ol><li>Calcular Tf a nivel de clúster</li>\n",
    "<li>Calcular IDF a nivel de clúster</li>\n",
    "<li>Generar puntuaciones para cada documento del clúster </li></ol>\n",
    "<h3> Palabras (Word2Vec)</h3>\n",
    "<ol><li>Obtener el vector del centroide: centroide = centroides[cluster_label]</li>\n",
    "<li>Encontrar las palabras más cercanas al centroide en el modelo Word2Vec\n",
    "        palabras_cercanas = model_w2v.wv.most_similar(positive=[centroide], topn=n)</li></ol>\n",
    "<h3> Documentos (Word2Vec)</h3>\n",
    "    <ol><li> Se utiliza la misma funcion que para TF-IDF</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6716d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import bz2\n",
    "from IPython.display import display, HTML\n",
    "import numpy as np\n",
    "import ast\n",
    "from gensim.corpora import Dictionary\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1a3eded",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('recursos/resultados_modelos.pkl', 'rb') as archivo:\n",
    "    resultados = pickle.load(archivo)\n",
    "    \n",
    "# Bigramas\n",
    "# with open('resultados_modelos_bi.pkl', 'rb') as archivo:\n",
    "#     resultados = pickle.load(archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48c9d4e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>adjusted_rand_score</th>\n",
       "      <th>normalized_mutual_info_score</th>\n",
       "      <th>fowlkes_mallows_score</th>\n",
       "      <th>bcubed_precision</th>\n",
       "      <th>bcubed_recall</th>\n",
       "      <th>bcubed_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.099076</td>\n",
       "      <td>0.393186</td>\n",
       "      <td>0.161949</td>\n",
       "      <td>0.449619</td>\n",
       "      <td>0.166230</td>\n",
       "      <td>0.170452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.116662</td>\n",
       "      <td>0.394557</td>\n",
       "      <td>0.180705</td>\n",
       "      <td>0.449484</td>\n",
       "      <td>0.172255</td>\n",
       "      <td>0.182132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.097570</td>\n",
       "      <td>0.395459</td>\n",
       "      <td>0.161686</td>\n",
       "      <td>0.445950</td>\n",
       "      <td>0.172077</td>\n",
       "      <td>0.177371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.106154</td>\n",
       "      <td>0.398824</td>\n",
       "      <td>0.171312</td>\n",
       "      <td>0.445362</td>\n",
       "      <td>0.185530</td>\n",
       "      <td>0.185768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.095128</td>\n",
       "      <td>0.390598</td>\n",
       "      <td>0.158885</td>\n",
       "      <td>0.442554</td>\n",
       "      <td>0.164820</td>\n",
       "      <td>0.171750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lista_resultados = resultados[\"kmeans_Tfidf\"]['resultados_ejecuciones']\n",
    "\n",
    "# Crear un DataFrame de pandas\n",
    "df = pd.DataFrame(lista_resultados)\n",
    "\n",
    "# Eliminar la columna 'confusion_matrix' ya que no se puede representar directamente en HTML\n",
    "df = df.drop(columns=['confusion_matrix'])\n",
    "\n",
    "# Convertir el DataFrame a HTML\n",
    "tabla_html = df.to_html(index=False)\n",
    "\n",
    "# Imprimir la tabla HTML\n",
    "display(HTML(tabla_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "813ab398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Media</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.231117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.230249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.223467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.220904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.219158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calcular la media para cada fila\n",
    "medias = df[['adjusted_rand_score', 'normalized_mutual_info_score', 'bcubed_f1']].mean(axis=1)\n",
    "\n",
    "# Añadir las medias como una nueva columna al DataFrame\n",
    "df['Media'] = medias\n",
    "\n",
    "df_ordenado = df.sort_values(by='Media',ascending=False)\n",
    "\n",
    "# Crear un nuevo dataframe solo con las medias\n",
    "df_medias = df_ordenado[['Media']]\n",
    "\n",
    "# Convertir el DataFrame a HTML\n",
    "tabla_html_medias = df_medias.to_html()\n",
    "\n",
    "display(HTML(tabla_html_medias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1d0d939",
   "metadata": {},
   "outputs": [],
   "source": [
    "etiquetas_predichas=resultados[\"kmeans_Tfidf\"]['etiquetas_predichas'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "626c48c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Runob\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator KMeans from version 1.6.1 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open('recursos/modelos_topicos/kmeans_Tfidf_ejecucion_123.pkl', 'rb') as archivo:\n",
    "    modelo = pickle.load(archivo)\n",
    "# with bz2.BZ2File('recursos/modelos_topicos_bi/kmeans_Tfidf_ejecucion_123.pkl.bz2', 'rb') as f:\n",
    "#     modelo = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29e53a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_documents_for_dictionary(tokenized_documents, filtered_words):\n",
    "    filtered_documents = []\n",
    "    for doc in tokenized_documents:\n",
    "        filtered_doc = [word for word in doc if word in filtered_words]\n",
    "        filtered_documents.append(filtered_doc)\n",
    "    return filtered_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb4dccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_preprocesado = pd.read_csv('df_preprocesado.csv', sep=';')\n",
    "dictionary = Dictionary.load('recursos/dictionary_filtrado_spacy.gensim')\n",
    "filtered_words = set(dictionary.token2id.keys())\n",
    "n_term=len(filtered_words)\n",
    "#preprocesado_documents=df_preprocesado['texto_preprocesado'].apply(ast.literal_eval)    \n",
    "#documents = filter_documents_for_dictionary(preprocesado_documents, filtered_words) \n",
    "with open('recursos/documents.pkl', 'rb') as archivo:\n",
    "    documents = pickle.load(archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "913db4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "documentos_como_cadenas = [\" \".join(doc) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e0a4315",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "matriz_tfidf = vectorizer.fit_transform(documentos_como_cadenas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "998efc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulario = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efe1e5a0-dbe4-4254-bf05-e0a0806274cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def obtener_clusters_ordenados(etiquetas):\n",
    " \n",
    "    # Contar el número de documentos por clúster\n",
    "    conteo_clusters = Counter(etiquetas)\n",
    "\n",
    "    # Eliminar el clúster residual (-1)\n",
    "    del conteo_clusters[-1]\n",
    "\n",
    "    # Ordenar por número de documentos (de mayor a menor)\n",
    "    clusters_ordenados = sorted(conteo_clusters.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return clusters_ordenados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d604a37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(26, 2515), (7, 2346), (43, 2253), (12, 2142), (59, 1972), (46, 1881), (24, 1754), (41, 1738), (25, 1656), (35, 1641), (4, 1555), (23, 1529), (37, 1480), (27, 1443), (54, 1408), (18, 1338), (29, 1317), (1, 1311), (33, 1281), (17, 1251), (48, 1242), (8, 1224), (30, 1184), (42, 1174), (50, 1157), (45, 1148), (39, 1146), (56, 1100), (34, 1065), (15, 1064), (44, 1040), (52, 1023), (53, 991), (13, 976), (55, 972), (3, 936), (38, 925), (9, 872), (6, 862), (20, 849), (51, 830), (0, 823), (2, 820), (57, 817), (60, 730), (58, 725), (28, 707), (49, 652), (40, 610), (31, 602), (14, 591), (36, 560), (16, 532), (21, 529), (32, 487), (10, 415), (5, 365), (11, 362), (22, 297), (47, 150), (19, 90)]\n"
     ]
    }
   ],
   "source": [
    "# Uso de la función\n",
    "# Asumiendo que `etiquetas` contiene las etiquetas generadas por el modelo KMeans\n",
    "clusters_ordenados = obtener_clusters_ordenados(etiquetas_predichas)\n",
    "print(clusters_ordenados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22fb6d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def obtener_palabras_representativas_por_cluster(centroides, vocabulario, etiquetas, n=10, n_top_clusters=20, output_excel_path=\"palabras_representativas_clusters.xlsx\"):\n",
    "  \n",
    "    # Obtener los clústeres ordenados por el número de documentos\n",
    "    clusters_ordenados = obtener_clusters_ordenados(etiquetas)\n",
    "\n",
    "    # Tomar los top N clústeres\n",
    "    top_clusters = clusters_ordenados[:n_top_clusters]\n",
    "\n",
    "    # Crear una lista para almacenar los datos de las palabras y su clúster\n",
    "    data = []\n",
    "\n",
    "    # Iterar sobre los clústeres seleccionados\n",
    "    for cluster_label, _ in top_clusters:\n",
    "        # Obtener el vector del centroide\n",
    "        centroide = centroides[cluster_label]\n",
    "\n",
    "        # Obtener los índices de las n palabras con valores más altos en el centroide\n",
    "        palabras_representativas_indices = np.argsort(centroide)[::-1][:n]\n",
    "\n",
    "        # Obtener las palabras representativas\n",
    "        palabras_representativas = [vocabulario[i] for i in palabras_representativas_indices]\n",
    "\n",
    "        # Unir las palabras representativas en una sola cadena separada por comas\n",
    "        palabras_string = \", \".join(palabras_representativas)\n",
    "\n",
    "        # Añadir el ID del clúster y las palabras al listado\n",
    "        data.append({\"Cluster ID\": cluster_label, \"Palabras\": palabras_string})\n",
    "\n",
    "    # Crear un DataFrame de pandas\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Exportar a Excel\n",
    "    df.to_excel(output_excel_path, index=False)\n",
    "\n",
    "    print(f\"Las palabras representativas de los clústeres se han exportado a '{output_excel_path}'.\")\n",
    "\n",
    "# Uso de la función\n",
    "# Asumiendo que `centroides`, `vocabulario`, y `etiquetas` están disponibles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05b7fa02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las palabras representativas de los clústeres se han exportado a 'palabras_representativas_clusters.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "centroides = modelo.cluster_centers_\n",
    "obtener_palabras_representativas_por_cluster(centroides, vocabulario, etiquetas_predichas,n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33737bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def imprimir_documentos_relevantes_clusters(etiquetas_predichas, documentos_preprocesados, documentos_originales, top_index, num_documentos=5, nombre_archivo=\"documentos_relevantes.xlsx\"):\n",
    "       \n",
    "    resultados_totales = []\n",
    " \n",
    "    for cluster_id in top_index:\n",
    "        documentos_cluster = [(i, documentos_preprocesados[i]) for i, etiqueta in enumerate(etiquetas_predichas) if etiqueta == cluster_id]\n",
    "\n",
    "        # Calcular TF\n",
    "        tf_cluster = defaultdict(int)\n",
    "        for _, documento in documentos_cluster:\n",
    "            for palabra in documento:\n",
    "                tf_cluster[palabra] += 1\n",
    "\n",
    "        # Calcular IDF\n",
    "        palabras_por_cluster = defaultdict(set)\n",
    "        for i, etiqueta in enumerate(etiquetas_predichas):\n",
    "            palabras_por_cluster[etiqueta].update(documentos_preprocesados[i])\n",
    "\n",
    "        num_clusters = len(set(etiquetas_predichas))\n",
    "        num_clusters_con_palabra = {}\n",
    "        idf_cluster = {}\n",
    "        peso_palabras = {}\n",
    "        for palabra in tf_cluster:\n",
    "            contador = 0\n",
    "            for palabras in palabras_por_cluster.values():\n",
    "                if palabra in palabras:\n",
    "                    contador += 1\n",
    "            num_clusters_con_palabra[palabra] = contador\n",
    "            frecuencia = num_clusters_con_palabra[palabra]\n",
    "            idf = np.log((1 + num_clusters) / (1 + frecuencia)) + 1\n",
    "            idf_cluster[palabra] = idf\n",
    "            peso_palabras[palabra] = tf_cluster[palabra] * idf_cluster[palabra]\n",
    "\n",
    "        # Evaluar documentos del clúster\n",
    "        puntuaciones_relevancia = []\n",
    "        for doc_id, documento in documentos_cluster:\n",
    "            # Calcular la frecuencia relativa de cada palabra\n",
    "            total_palabras_doc = len(documento)\n",
    "            puntuacion = np.array([peso_palabras.get(palabra, 0) * (documento.count(palabra) / total_palabras_doc) for palabra in documento])\n",
    "            puntuacion_final = sum(puntuacion)\n",
    "\n",
    "            # Cortar los primeros 300 caracteres del documento original\n",
    "            documento_recortado = documentos_originales[doc_id][:300]\n",
    "\n",
    "            puntuaciones_relevancia.append((doc_id, cluster_id, documento_recortado, puntuacion_final))\n",
    "\n",
    "        # Ordenar por puntuación\n",
    "        puntuaciones_relevancia_ordenadas = sorted(puntuaciones_relevancia, key=lambda x: x[3], reverse=True)[:num_documentos]\n",
    "\n",
    "        # Añadir resultados de este cluster\n",
    "        resultados_totales.extend(puntuaciones_relevancia_ordenadas)\n",
    "\n",
    "    # Verificar que hay datos antes de crear el DataFrame\n",
    "    if resultados_totales:\n",
    "        df = pd.DataFrame(resultados_totales, columns=[\"ID\", \"ID de Cluster\", \"Documento (200 caracteres)\", \"Puntuación\"])\n",
    "\n",
    "        # Guardar en formato CSV, XLSX o ODS según el nombre de archivo\n",
    "        if nombre_archivo.endswith('.csv'):\n",
    "            df.to_csv(nombre_archivo, index=False, encoding=\"utf-8\")\n",
    "        elif nombre_archivo.endswith('.ods'):\n",
    "            df.to_excel(nombre_archivo, index=False, engine=\"odf\")\n",
    "        else:\n",
    "            df.to_excel(nombre_archivo, index=False, engine=\"openpyxl\")\n",
    "        print(f\"Archivo guardado: {nombre_archivo}\")\n",
    "    else:\n",
    "        print(\"No hay documentos relevantes para los clusters indicados.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc325fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#documentos_originales=df_preprocesado['texto']\n",
    "with bz2.BZ2File('recursos/documentos_originales.pkl.bz2', 'rb') as f:\n",
    "    documentos_originales = pickle.load(f)\n",
    "# Obtener los clústeres ordenados por el número de documentos\n",
    "clusters_ordenados = obtener_clusters_ordenados(etiquetas_predichas)\n",
    "\n",
    "# Tomar los top N clústeres\n",
    "top_clusters = clusters_ordenados[:20]\n",
    "top_clusters_ids = [cluster_id for cluster_id, _ in top_clusters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "acfc2edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30, 4, 3, 18, 1, 32, 13, 16, 40, 37, 21, 10, 23, 20, 9, 28, 27, 34, 59, 22]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_clusters_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ea8572",
   "metadata": {},
   "outputs": [],
   "source": [
    "imprimir_documentos_relevantes_clusters(etiquetas_predichas, documents, documentos_originales, top_clusters_ids, num_documentos=5, nombre_archivo=\"documentos_relevantes_kmeans_tfidf.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd42d5a3",
   "metadata": {},
   "source": [
    "# Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdecdbf7-1612-4f24-ac8b-4378ce412b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('recurso/resultados_modelos.pkl', 'rb') as archivo:\n",
    "    resultados = pickle.load(archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1443c1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>adjusted_rand_score</th>\n",
       "      <th>normalized_mutual_info_score</th>\n",
       "      <th>fowlkes_mallows_score</th>\n",
       "      <th>bcubed_precision</th>\n",
       "      <th>bcubed_recall</th>\n",
       "      <th>bcubed_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.138535</td>\n",
       "      <td>0.420432</td>\n",
       "      <td>0.216817</td>\n",
       "      <td>0.471478</td>\n",
       "      <td>0.145074</td>\n",
       "      <td>0.181187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.130193</td>\n",
       "      <td>0.416937</td>\n",
       "      <td>0.207329</td>\n",
       "      <td>0.468674</td>\n",
       "      <td>0.141263</td>\n",
       "      <td>0.173602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.122815</td>\n",
       "      <td>0.417390</td>\n",
       "      <td>0.198260</td>\n",
       "      <td>0.470868</td>\n",
       "      <td>0.136772</td>\n",
       "      <td>0.167968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.127586</td>\n",
       "      <td>0.416247</td>\n",
       "      <td>0.203817</td>\n",
       "      <td>0.469811</td>\n",
       "      <td>0.141752</td>\n",
       "      <td>0.171377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.128947</td>\n",
       "      <td>0.416050</td>\n",
       "      <td>0.204385</td>\n",
       "      <td>0.465154</td>\n",
       "      <td>0.144416</td>\n",
       "      <td>0.172522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lista_resultados = resultados[\"kmeans_word2vec_250\"]['resultados_ejecuciones']\n",
    "\n",
    "#lista_resultados = resultados[\"kmeans_word2vec_100\"]['resultados_ejecuciones'] Para bigramas\n",
    "\n",
    "\n",
    "# Crear un DataFrame de pandas\n",
    "df = pd.DataFrame(lista_resultados)\n",
    "\n",
    "# Eliminar la columna 'confusion_matrix' ya que no se puede representar directamente en HTML\n",
    "df = df.drop(columns=['confusion_matrix'])\n",
    "\n",
    "# Convertir el DataFrame a HTML\n",
    "tabla_html = df.to_html(index=False)\n",
    "\n",
    "# Imprimir la tabla HTML\n",
    "display(HTML(tabla_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbbcce10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Media</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.246718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.240244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.239173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.238403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.236058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calcular la media para cada fila\n",
    "medias = df[['adjusted_rand_score', 'normalized_mutual_info_score', 'bcubed_f1']].mean(axis=1)\n",
    "\n",
    "# Añadir las medias como una nueva columna al DataFrame\n",
    "df['Media'] = medias\n",
    "\n",
    "df_ordenado = df.sort_values(by='Media',ascending=False)\n",
    "\n",
    "# Crear un nuevo dataframe solo con las medias\n",
    "df_medias = df_ordenado[['Media']]\n",
    "\n",
    "# Convertir el DataFrame a HTML\n",
    "tabla_html_medias = df_medias.to_html()\n",
    "\n",
    "display(HTML(tabla_html_medias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5500e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "etiquetas_predichas=resultados[\"kmeans_word2vec_250\"]['etiquetas_predichas'][0]\n",
    "# etiquetas_predichas=resultados[\"kmeans_word2vec_100\"]['etiquetas_predichas'][1] Para bigramas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c648bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resultado/modelos_topicos/kmeans_word2vec_250_ejecucion_42.pkl', 'rb') as archivo:\n",
    "    modelo = pickle.load(archivo)\n",
    "# Para bigramas\n",
    "# with open('resultado/modelos_topicos_bi/kmeans_word2vec_100_ejecucion_123.pkl', 'rb') as archivo:\n",
    "#     modelo = pickle.load(archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bafaae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_palabras_representativas_kmeans_w2v2(model_w2v, labels, centroides, n=15,n_top_clusters=20,output_excel_path=\"palabras_representativas_kmeans_w2v.xlsx\"):\n",
    " \n",
    "    # Obtener los clústeres ordenados por el número de documentos\n",
    "    clusters_ordenados = obtener_clusters_ordenados(labels)\n",
    "\n",
    "    # Tomar los top N clústeres\n",
    "    top_clusters = clusters_ordenados[:n_top_clusters]\n",
    "    cluster_palabras_representativas = {}\n",
    "# Crear una lista para almacenar los datos de las palabras y su clúster\n",
    "    data = []\n",
    "    for cluster_label, _ in top_clusters:\n",
    "        # Obtener el centroide del clúster\n",
    "        centroide = centroides[cluster_label]\n",
    "\n",
    "        # Encontrar las palabras más cercanas al centroide en el modelo Word2Vec\n",
    "        palabras_cercanas = model_w2v.wv.most_similar(positive=[centroide], topn=n)\n",
    "\n",
    "        cluster_palabras_representativas[cluster_label] = [palabra for palabra, _ in palabras_cercanas]\n",
    "\n",
    "       # Unir las palabras representativas en una sola cadena separada por comas\n",
    "        palabras_string = \", \".join(cluster_palabras_representativas[cluster_label])\n",
    "\n",
    "        # Añadir el ID del clúster y las palabras al listado\n",
    "        data.append({\"Cluster ID\": cluster_label, \"Palabras\": palabras_string})\n",
    "\n",
    "    # Crear un DataFrame de pandas\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Exportar a Excel\n",
    "    df.to_excel(output_excel_path, index=False)\n",
    "\n",
    "    print(f\"Las palabras representativas de los clústeres se han exportado a '{output_excel_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d714d1d6-7fe4-478b-9a57-0672ee6ad44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_ordenados = obtener_clusters_ordenados(etiquetas_predichas)\n",
    "top_clusters = clusters_ordenados[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cad84820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las palabras representativas de los clústeres se han exportado a 'palabras_representativas_kmeans_w2v.xlsx'.\n"
     ]
    }
   ],
   "source": [
    " # Cargar el modelo Word2Vec y las etiquetas predichas\n",
    "\n",
    "modelo_w2v_cargado = Word2Vec.load(\"recurso/w2v_250_epochs.model\")\n",
    "centroides = modelo.cluster_centers_\n",
    "\n",
    "# Obtener las palabras representativas\n",
    "palabras_representativas = obtener_palabras_representativas_kmeans_w2v2(modelo_w2v_cargado, etiquetas_predichas, centroides)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f707ce20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_preprocesado = pd.read_csv('df_preprocesado.csv', sep=';')\n",
    "# documentos_originales=df_preprocesado['texto']\n",
    "with bz2.BZ2File('recursos/documentos_originales.pkl.bz2', 'rb') as f:\n",
    "    documentos_originales = pickle.load(f)\n",
    "# Obtener los clústeres ordenados por el número de documentos\n",
    "clusters_ordenados = obtener_clusters_ordenados(etiquetas_predichas)\n",
    "\n",
    "# Tomar los top N clústeres\n",
    "top_clusters = clusters_ordenados[:20]\n",
    "top_clusters_ids = [cluster_id for cluster_id, _ in top_clusters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1e650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imprimir_documentos_relevantes_clusters(etiquetas_predichas, documents, documentos_originales, top_clusters_ids, num_documentos=5, nombre_archivo=\"documentos_relevantes_kmeans_word2vecv1.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
