{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d269fb00",
   "metadata": {},
   "source": [
    "## Palabras\n",
    "modelo.cluster_word_distribution\n",
    "## Documentos\n",
    "<ol><li> Por frecuencia:\n",
    "<ol><li> Extraer palabras clave del clúster</li>\n",
    "<li> Contar coincidencias y calcular puntuación de relevancia:puntuacion += palabras_clave_ponderadas[str(palabra)]  </li>\n",
    "<li>Ordenar documentos por puntuación de relevancia</li></ol></li>\n",
    "<li> Por Tf-idf   \n",
    "<ol><li>Extraer palabras clave del clúster</li>\n",
    "     <li> Obtener índices de palabras clave en la matriz TF-IDF\n",
    "    <ol><li>TF-IDF medio en el corpus:palabras_clave_ponderadas[palabra] = np.mean(tfidf_matrix[:, idx].toarray()) </li> \n",
    "    <li>Calcular la media solo dentro del clúster: palabras_clave_ponderadas[palabra] = np.mean(tfidf_matrix[indices_cluster, idx].toarray()) </li></ol></li>\n",
    "    <li> Por Tf-idf por cluster en vez de por documento <strong>(opción final elegida)</strong></li>  \n",
    "\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6716d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from IPython.display import display, HTML\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.corpora import Dictionary, MmCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1a3eded",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('recurso/resultados_modelos.pkl', 'rb') as archivo:\n",
    "    resultados = pickle.load(archivo)\n",
    "    \n",
    "# Para bigramas    \n",
    "# with open('recurso/resultados_modelos_bi.pkl', 'rb') as archivo:\n",
    "#     resultados = pickle.load(archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e897d850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'adjusted_rand_score': 0.20750005048726017,\n",
       "  'normalized_mutual_info_score': 0.4500232582107795,\n",
       "  'confusion_matrix': array([[ 0,  0,  0, ...,  0,  0,  0],\n",
       "         [ 0,  0,  0, ...,  0,  0,  0],\n",
       "         [ 9,  0, 49, ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0, ...,  0,  0,  0],\n",
       "         [ 0,  0,  0, ...,  0,  0,  0],\n",
       "         [ 0,  0,  1, ...,  0,  0,  0]], dtype=int64),\n",
       "  'fowlkes_mallows_score': 0.27961404729597233,\n",
       "  'bcubed_precision': 0.4643622245288614,\n",
       "  'bcubed_recall': 0.2202949308471145,\n",
       "  'bcubed_f1': 0.24446687554129068},\n",
       " {'adjusted_rand_score': 0.2026919322006004,\n",
       "  'normalized_mutual_info_score': 0.44244498826099543,\n",
       "  'confusion_matrix': array([[ 0,  0,  0, ...,  0,  0,  0],\n",
       "         [ 0,  0,  0, ...,  0,  0,  0],\n",
       "         [10,  6,  5, ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0, ...,  0,  0,  0],\n",
       "         [ 0,  0,  0, ...,  0,  0,  0],\n",
       "         [ 0,  2,  3, ...,  0,  0,  0]], dtype=int64),\n",
       "  'fowlkes_mallows_score': 0.2768484321419279,\n",
       "  'bcubed_precision': 0.4582524309512777,\n",
       "  'bcubed_recall': 0.22553825690033388,\n",
       "  'bcubed_f1': 0.23716479334236387},\n",
       " {'adjusted_rand_score': 0.21532751092362493,\n",
       "  'normalized_mutual_info_score': 0.44803970142514254,\n",
       "  'confusion_matrix': array([[ 0,  0,  0, ...,  0,  0,  0],\n",
       "         [ 0,  0,  0, ...,  0,  0,  0],\n",
       "         [ 0,  4, 27, ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0, ...,  0,  0,  0],\n",
       "         [ 0,  0,  0, ...,  0,  0,  0],\n",
       "         [ 0,  0,  2, ...,  0,  0,  0]], dtype=int64),\n",
       "  'fowlkes_mallows_score': 0.2871114321946255,\n",
       "  'bcubed_precision': 0.4662282908159871,\n",
       "  'bcubed_recall': 0.2476574199958365,\n",
       "  'bcubed_f1': 0.2530889718608979},\n",
       " {'adjusted_rand_score': 0.21615592370441805,\n",
       "  'normalized_mutual_info_score': 0.4517592060702064,\n",
       "  'confusion_matrix': array([[ 0,  0,  0, ...,  0,  0,  0],\n",
       "         [ 0,  0,  0, ...,  0,  0,  0],\n",
       "         [ 0, 49, 37, ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0, ...,  0,  0,  0],\n",
       "         [ 0,  0,  0, ...,  0,  0,  0],\n",
       "         [ 0,  1,  0, ...,  0,  0,  0]], dtype=int64),\n",
       "  'fowlkes_mallows_score': 0.28937593821295543,\n",
       "  'bcubed_precision': 0.4705972299924089,\n",
       "  'bcubed_recall': 0.24131779450480426,\n",
       "  'bcubed_f1': 0.2546357199394474},\n",
       " {'adjusted_rand_score': 0.19563494392788586,\n",
       "  'normalized_mutual_info_score': 0.444791496326123,\n",
       "  'confusion_matrix': array([[  0,   0,   0, ...,   0,   0,   0],\n",
       "         [  0,   0,   0, ...,   0,   0,   0],\n",
       "         [  0,   0, 118, ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0, ...,   0,   0,   0],\n",
       "         [  0,   0,   2, ...,   0,   0,   0],\n",
       "         [  0,   0,   3, ...,   0,   0,   0]], dtype=int64),\n",
       "  'fowlkes_mallows_score': 0.2685637578006224,\n",
       "  'bcubed_precision': 0.46107442114763225,\n",
       "  'bcubed_recall': 0.21694825807189141,\n",
       "  'bcubed_f1': 0.23456472004528311}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados[\"gsdmm_100\"]['resultados_ejecuciones']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7185da95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>adjusted_rand_score</th>\n",
       "      <th>normalized_mutual_info_score</th>\n",
       "      <th>fowlkes_mallows_score</th>\n",
       "      <th>bcubed_precision</th>\n",
       "      <th>bcubed_recall</th>\n",
       "      <th>bcubed_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.207500</td>\n",
       "      <td>0.450023</td>\n",
       "      <td>0.279614</td>\n",
       "      <td>0.464362</td>\n",
       "      <td>0.220295</td>\n",
       "      <td>0.244467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.202692</td>\n",
       "      <td>0.442445</td>\n",
       "      <td>0.276848</td>\n",
       "      <td>0.458252</td>\n",
       "      <td>0.225538</td>\n",
       "      <td>0.237165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.215328</td>\n",
       "      <td>0.448040</td>\n",
       "      <td>0.287111</td>\n",
       "      <td>0.466228</td>\n",
       "      <td>0.247657</td>\n",
       "      <td>0.253089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.216156</td>\n",
       "      <td>0.451759</td>\n",
       "      <td>0.289376</td>\n",
       "      <td>0.470597</td>\n",
       "      <td>0.241318</td>\n",
       "      <td>0.254636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.195635</td>\n",
       "      <td>0.444791</td>\n",
       "      <td>0.268564</td>\n",
       "      <td>0.461074</td>\n",
       "      <td>0.216948</td>\n",
       "      <td>0.234565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lista_resultados = resultados[\"gsdmm_100\"]['resultados_ejecuciones']\n",
    "\n",
    "# Crear un DataFrame de pandas\n",
    "df = pd.DataFrame(lista_resultados)\n",
    "\n",
    "# Eliminar la columna 'confusion_matrix' ya que no se puede representar directamente en HTML\n",
    "df = df.drop(columns=['confusion_matrix'])\n",
    "\n",
    "# Convertir el DataFrame a HTML\n",
    "tabla_html = df.to_html(index=False)\n",
    "\n",
    "# Imprimir la tabla HTML\n",
    "display(HTML(tabla_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b41fc4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Media</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.307517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.305485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.300663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.294101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.291664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calcular la media para cada fila\n",
    "medias = df[['adjusted_rand_score', 'normalized_mutual_info_score', 'bcubed_f1']].mean(axis=1)\n",
    "\n",
    "# Añadir las medias como una nueva columna al DataFrame\n",
    "df['Media'] = medias\n",
    "\n",
    "df_ordenado = df.sort_values(by='Media',ascending=False)\n",
    "\n",
    "# Crear un nuevo dataframe solo con las medias\n",
    "df_medias = df_ordenado[['Media']]\n",
    "\n",
    "# Convertir el DataFrame a HTML\n",
    "tabla_html_medias = df_medias.to_html()\n",
    "\n",
    "display(HTML(tabla_html_medias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1d0d939",
   "metadata": {},
   "outputs": [],
   "source": [
    "etiquetas_predichas=resultados[\"gsdmm_100\"]['etiquetas_predichas'][3]\n",
    "# Para bigramas\n",
    "# etiquetas_predichas=resultados[\"gsdmm\"]['etiquetas_predichas'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "626c48c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resultado/modelos_topicos/gsdmm_100_ejecucion_890.pkl', 'rb') as archivo:\n",
    "    modelo = pickle.load(archivo)\n",
    "# with open('modelos_topicos_bi/gsdmm_ejecucion_123.pkl', 'rb') as archivo:\n",
    "#     modelo = pickle.load(archivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3198c599",
   "metadata": {},
   "source": [
    "### Obtener las palabras relevantes de los tópicos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10e1d3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents per topic : [  29 1915 1621 1932 2289 1928 1062 1104   41  445   40  345   48 4404\n",
      " 1268   48 1696   11  178 2358  246 1754 1069  691 2778   21 1239   54\n",
      " 1009 3976 1864 1398  395  409 2425  100 3098  286  859  668  557 1063\n",
      "  561   75  935  454 1673   23 1817   95 2064  227   61 1297 1402  121\n",
      "  388 2184   34  445 3878]\n",
      "********************\n",
      "Most important clusters (by number of docs inside): [13 29 60 36 24 34 19  4 57 50  3  5  1 30 48 21 16 46  2 54 31]\n",
      "********************\n",
      "Cluster 13 : [('semaforo', 6588), ('bache', 5735), ('calle', 5333), ('solicitar', 4018), ('reparacion', 3845), ('avenida', 3711), ('fundido', 3495), ('paseo', 1846), ('rama', 1532), ('tapar', 1023), ('san', 710), ('plaza', 525), ('poda', 512), ('situado', 509), ('podar', 508)]\n",
      " — — — — — — — — — \n",
      "Cluster 29 : [('farola', 5030), ('luz', 5026), ('punto', 3509), ('calle', 3410), ('matricular', 3168), ('apagado', 2064), ('alumbrado', 1146), ('fundido', 1061), ('zona', 861), ('saludo', 785), ('iluminacion', 772), ('noche', 749), ('tramo', 703), ('parque', 686), ('gracia', 653)]\n",
      " — — — — — — — — — \n",
      "Cluster 60 : [('calle', 4293), ('zona', 2802), ('parque', 2151), ('año', 1898), ('zaragoza', 1889), ('persona', 1858), ('ciudad', 1740), ('ayuntamiento', 1706), ('vecino', 1504), ('vehiculo', 1503), ('pasar', 1443), ('policia', 1368), ('queja', 1342), ('servicio', 1287), ('barrio', 1277)]\n",
      " — — — — — — — — — \n",
      "Cluster 36 : [('contenedor', 6743), ('basura', 3517), ('calle', 2974), ('cubo', 1115), ('carton', 754), ('lleno', 734), ('gracia', 721), ('roto', 645), ('recogida', 632), ('saludo', 631), ('dejar', 607), ('solicitar', 601), ('vecino', 597), ('papel', 596), ('reciclaje', 536)]\n",
      " — — — — — — — — — \n",
      "Cluster 24 : [('baldosa', 2822), ('calle', 2639), ('acera', 2405), ('roto', 1225), ('levantado', 853), ('caida', 730), ('suelto', 612), ('persona', 599), ('numero', 585), ('zona', 560), ('gracia', 540), ('saludo', 507), ('altura', 493), ('peligro', 485), ('tapa', 435)]\n",
      " — — — — — — — — — \n",
      "Cluster 34 : [('arbol', 3173), ('zona', 1794), ('calle', 1665), ('parque', 1411), ('cesped', 1093), ('año', 811), ('plantar', 781), ('riego', 620), ('alcorqu', 577), ('gracia', 572), ('verde', 567), ('seco', 534), ('arbolado', 527), ('saludo', 485), ('barrio', 468)]\n",
      " — — — — — — — — — \n",
      "Cluster 19 : [('parque', 4217), ('infantil', 1917), ('niño', 1744), ('zona', 1569), ('columpio', 947), ('roto', 855), ('plaza', 843), ('tobogan', 583), ('gracia', 548), ('juego', 517), ('calle', 502), ('suelo', 499), ('banco', 467), ('año', 455), ('barrio', 449)]\n",
      " — — — — — — — — — \n",
      "Cluster 4 : [('calle', 3065), ('zona', 2042), ('aparcamiento', 1822), ('aparcar', 1636), ('coche', 1419), ('vehiculo', 1406), ('moto', 1241), ('plaza', 1163), ('acera', 1143), ('estacionamiento', 766), ('gracia', 644), ('saludo', 535), ('parking', 535), ('garaje', 509), ('paso', 474)]\n",
      " — — — — — — — — — \n",
      "Cluster 57 : [('arbol', 3848), ('rama', 2099), ('calle', 1948), ('poda', 1248), ('podar', 609), ('caer', 606), ('acera', 569), ('gracia', 521), ('saludo', 459), ('peligro', 455), ('altura', 446), ('ventana', 433), ('año', 430), ('zona', 414), ('pasar', 380)]\n",
      " — — — — — — — — — \n",
      "Cluster 50 : [('calle', 3368), ('paso', 1883), ('semaforo', 1786), ('peaton', 1260), ('coche', 1176), ('vehiculo', 1035), ('cruce', 854), ('pasar', 840), ('velocidad', 761), ('colegio', 730), ('trafico', 713), ('cebra', 697), ('salida', 665), ('gracia', 654), ('barrio', 646)]\n",
      " — — — — — — — — — \n",
      "Cluster 3 : [('error', 660), ('ciudadano', 556), ('tarjeta', 500), ('gracia', 466), ('web', 456), ('servicio', 453), ('intentar', 443), ('electronico', 432), ('pagina', 427), ('saludo', 421), ('solicitar', 407), ('certificado', 379), ('expediente', 374), ('problema', 358), ('solicitud', 355)]\n",
      " — — — — — — — — — \n",
      "Cluster 5 : [('calle', 1684), ('zona', 1362), ('solar', 1206), ('limpieza', 1144), ('basura', 726), ('parque', 537), ('hierba', 502), ('barrio', 452), ('rata', 443), ('acera', 437), ('limpiar', 434), ('gracia', 425), ('suciedad', 413), ('año', 386), ('lleno', 384)]\n",
      " — — — — — — — — — \n",
      "Cluster 1 : [('calle', 1415), ('ruido', 1392), ('vecino', 1075), ('noche', 847), ('policia', 769), ('hora', 730), ('zona', 622), ('bar', 622), ('semana', 559), ('barrio', 548), ('local', 532), ('mañana', 471), ('pasar', 468), ('año', 462), ('parque', 452)]\n",
      " — — — — — — — — — \n",
      "Cluster 30 : [('informacion', 919), ('zaragoza', 769), ('año', 628), ('gracia', 561), ('ayuntamiento', 489), ('saludo', 481), ('pagina', 468), ('publico', 459), ('solicitud', 366), ('persona', 319), ('gustar', 310), ('municipal', 305), ('gracias', 291), ('querer', 290), ('servicio', 283)]\n",
      " — — — — — — — — — \n",
      "Cluster 48 : [('autobus', 2440), ('linea', 2257), ('bus', 1254), ('servicio', 1103), ('parada', 1089), ('frecuencia', 914), ('minuto', 903), ('hora', 836), ('llegar', 798), ('tranvia', 692), ('esperar', 664), ('transporte', 627), ('pasar', 555), ('publico', 505), ('tiempo', 503)]\n",
      " — — — — — — — — — \n",
      "Cluster 21 : [('calle', 3454), ('limpieza', 2100), ('acera', 1234), ('limpiar', 829), ('perro', 796), ('pasar', 778), ('suciedad', 687), ('zona', 636), ('sucio', 499), ('agua', 456), ('gracia', 443), ('barrio', 437), ('saludo', 372), ('lleno', 364), ('ver', 353)]\n",
      " — — — — — — — — — \n",
      "Cluster 16 : [('calle', 2424), ('calzada', 1096), ('bache', 700), ('agujero', 607), ('asfalto', 597), ('paso', 532), ('socavon', 482), ('acera', 407), ('gracia', 380), ('saludo', 354), ('vehiculo', 345), ('coche', 329), ('altura', 323), ('peaton', 319), ('asfaltado', 318)]\n",
      " — — — — — — — — — \n",
      "Cluster 46 : [('carril', 2990), ('bici', 1872), ('semaforo', 947), ('calle', 786), ('peaton', 643), ('paso', 574), ('avenida', 571), ('vehiculo', 551), ('gracia', 488), ('via', 466), ('zona', 459), ('rotonda', 458), ('bicicleta', 454), ('paseo', 447), ('puente', 429)]\n",
      " — — — — — — — — — \n",
      "Cluster 2 : [('calle', 2710), ('basura', 1672), ('contenedor', 1062), ('limpieza', 1011), ('zona', 628), ('suciedad', 604), ('olor', 505), ('vecino', 497), ('dejar', 475), ('perro', 448), ('acera', 411), ('pasar', 356), ('gracia', 354), ('bolsa', 335), ('saludo', 330)]\n",
      " — — — — — — — — — \n",
      "Cluster 54 : [('papelera', 1313), ('parque', 1189), ('calle', 979), ('zona', 913), ('limpieza', 818), ('basura', 621), ('lleno', 472), ('perro', 370), ('suciedad', 357), ('gracia', 340), ('barrio', 310), ('limpiar', 267), ('pasar', 260), ('cristal', 252), ('saludo', 247)]\n",
      " — — — — — — — — — \n",
      "Cluster 31 : [('calle', 971), ('paloma', 742), ('parque', 682), ('zona', 624), ('plaga', 598), ('rata', 558), ('problema', 448), ('gracia', 398), ('saludo', 317), ('mosca', 275), ('favor', 269), ('vecino', 267), ('niño', 266), ('año', 256), ('negro', 256)]\n",
      " — — — — — — — — — \n"
     ]
    }
   ],
   "source": [
    "def top_words(cluster_word_distribution, top_cluster, values):\n",
    "    for cluster in top_cluster:\n",
    "        sort_dicts = sorted(\n",
    "            modelo.cluster_word_distribution[cluster].items(),\n",
    "            key=lambda k: k[1],\n",
    "            reverse=True,\n",
    "        )[:values]\n",
    "        print('Cluster %s : %s'%(cluster,sort_dicts))\n",
    "        print(' — — — — — — — — — ')\n",
    "\n",
    "doc_count = np.array(modelo.cluster_doc_count)\n",
    "print('Number of documents per topic :', doc_count)\n",
    "print('*'*20)\n",
    "\n",
    "# Topics sorted by the number of document they are allocated to\n",
    "top_index = doc_count.argsort()[-21:][::-1]\n",
    "print('Most important clusters (by number of docs inside):', top_index)\n",
    "print('*'*20)\n",
    "\n",
    "\n",
    "# Show the top 10 words in term frequency for each cluster \n",
    "top_words(modelo.cluster_word_distribution, top_index, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3a392cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_palabras_topicos_cluster_excel(modelo, lista_topicos, num_words=15, output_excel_path=\"palabras_topicos_GSDMM.xlsx\"):\n",
    "   \n",
    "\n",
    "    data = []\n",
    "\n",
    "    for topic_id in lista_topicos:\n",
    "        # Obtener las palabras más probables para el tópico actual\n",
    "        palabras_probables = sorted(\n",
    "            modelo.cluster_word_distribution[topic_id].items(),\n",
    "            key=lambda k: k[1],\n",
    "            reverse=True,\n",
    "        )[:num_words]\n",
    "\n",
    "        # Extraer solo las palabras y unirlas en una cadena separada por comas\n",
    "        palabras = [palabra for palabra, probabilidad in palabras_probables]\n",
    "        palabras_str = \", \".join(palabras)\n",
    "\n",
    "        # Agregar la cadena a la lista de datos\n",
    "        data.append({\"Tópico\": topic_id, \"Palabras\": palabras_str})\n",
    "\n",
    "    # Crear un DataFrame de pandas a partir de los datos\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Exportar el DataFrame a un archivo Excel\n",
    "    df.to_excel(output_excel_path, index=False)\n",
    "\n",
    "    print(f\"Las palabras de los tópicos se han exportado a '{output_excel_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62ed6781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las palabras de los tópicos se han exportado a 'palabras_topicos_GSDMM.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "generar_palabras_topicos_cluster_excel(modelo, top_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a453bc4b",
   "metadata": {},
   "source": [
    "## Obtener documentos más representativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "463212d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imprimir_documentos_relevantes_cluster_etiquetas(etiquetas_predichas, documentos_preprocesados,documentos_originales, cluster_id, num_documentos=5, num_palabras_clave=10, mgp=None):\n",
    "\n",
    "\n",
    "    # 1. Extraer palabras clave del clúster\n",
    "    palabras_clave = sorted(\n",
    "        mgp.cluster_word_distribution[cluster_id].items(),\n",
    "        key=lambda k: k[1],\n",
    "        reverse=True,\n",
    "    )[:num_palabras_clave]\n",
    "    # Ponderación de palabras clave (usando la frecuencia como ponderación)\n",
    "    palabras_clave_ponderadas = {str(palabra): frecuencia for palabra, frecuencia in palabras_clave}\n",
    "\n",
    "    # 2. Contar coincidencias y calcular puntuación de relevancia\n",
    "    puntuaciones_relevancia = []\n",
    "    for i, documento in enumerate(documentos_preprocesados):\n",
    "        if etiquetas_predichas[i] == cluster_id:\n",
    "            puntuacion = 0\n",
    "            for palabra in documento:\n",
    "             \n",
    "                if palabra in palabras_clave_ponderadas:\n",
    "                    \n",
    "                    puntuacion += palabras_clave_ponderadas[str(palabra)]\n",
    "            puntuaciones_relevancia.append((documentos_originales[i], puntuacion))\n",
    "\n",
    "    # 3. Ordenar documentos por puntuación de relevancia\n",
    "    puntuaciones_relevancia_ordenadas = sorted(puntuaciones_relevancia, key=lambda x: x[1], reverse=True)[:num_documentos]\n",
    "\n",
    "    # Imprimir resultados\n",
    "    print(f\"Documentos más relevantes del clúster {cluster_id}:\")\n",
    "    for documento, puntuacion in puntuaciones_relevancia_ordenadas:\n",
    "        print(f\"  Documento: {documento}, Puntuación: {puntuacion}\")\n",
    "        print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "581ebfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_preprocesado = pd.read_csv('df_preprocesado.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a180d748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# documentos=df_preprocesado['texto_preprocesado'].apply(ast.literal_eval) \n",
    "# documentos_originales=df_preprocesado['texto']\n",
    "with open('recursos/documents.pkl', 'rb') as f:\n",
    "    documentos = pickle.load(f)\n",
    "with bz2.BZ2File('recursos/documentos_originales.pkl.bz2', 'rb') as f:\n",
    "    documentos_originales = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88465500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos más relevantes del clúster 13:\n",
      "  Documento: Baches en la avenida San José con la avenida Cesáreo Alierta Hay varios baches en la avenida San José con la avenida Cesáreo Alierta.\r\n",
      "Solicito la reparación de los baches.\r\n",
      "\r\n",
      "La reparación ya se solicitó hace 77 días el 23/11/2022.\r\n",
      "La reparación ya se solicitó hace 57 días el 14/12/2022.\r\n",
      "La reparación ya se solicitó hace 10 días el 30/01/2023., Puntuación: 63501\n",
      "--------------------\n",
      "  Documento: Semáforo fundido en la avenida Madrid entre la calle Don Pedro de Luna y la calle Sangenis En la avenida Madrid entre la calle Don Pedro de Luna y la calle Sangenis el semáforo está fundido.\r\n",
      "Solicito la reparación del semáforo., Puntuación: 63371\n",
      "--------------------\n",
      "  Documento: Baches en el paseo de Cuéllar con el Centro Regional de Mando Hay varios baches en el paseo de Cuéllar con el Centro Regional de Mando.\r\n",
      "Solicito la reparación de los baches.\r\n",
      "\r\n",
      "La reparación ya se solicitó hace 379 días el 22/01/2021.\r\n",
      "La reparación ya se solicitó hace 206 días el 14/07/2021.\r\n",
      "La reparación ya se solicitó hace 125 días el 03/10/2021.\r\n",
      "La reparación ya se solicitó hace 42 días el 25/12/2021., Puntuación: 60212\n",
      "--------------------\n",
      "  Documento: Baches en la calle Don Jaime con la plaza José Sinués Hay varios baches en la calle Don Jaime con la plaza José Sinués.\r\n",
      "Solicito la reparación de los baches.\r\n",
      "\r\n",
      "La reparación ya se solicitó hace 176 días el 16/08/2021. \r\n",
      "La reparación ya se solicitó hace 105 días el 26/10/2021. \r\n",
      "La reparación ya se solicitó hace 59 días el 10/12/2021. , Puntuación: 59323\n",
      "--------------------\n",
      "  Documento: Baches en la calle Gascón de Gotor entre la calle Sevilla y la calle Porvenir Hay varios baches en la calle Gascón de Gotor entre la calle Sevilla y la calle Porvenir.\r\n",
      "Solicito la reparación de los baches., Puntuación: 57066\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "cluster_a_imprimir = 13  # Imprimir documentos del clúster 0\n",
    "numero_documentos_a_imprimir = 5 # Imprimir los n documentos más relevantes\n",
    "imprimir_documentos_relevantes_cluster_etiquetas(etiquetas_predichas, documentos,documentos_originales,cluster_a_imprimir, numero_documentos_a_imprimir, mgp=modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2318961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_documents_for_dictionary(tokenized_documents, filtered_words):\n",
    "    filtered_documents = []\n",
    "    for doc in tokenized_documents:\n",
    "        filtered_doc = [word for word in doc if word in filtered_words]\n",
    "        filtered_documents.append(filtered_doc)\n",
    "    return filtered_documents\n",
    "#df_preprocesado = pd.read_csv('df_preprocesado.csv', sep=';')\n",
    "# dictionary = Dictionary.load('recurso/dictionary_filtrado_spacy.gensim')\n",
    "# filtered_words = set(dictionary.token2id.keys())\n",
    "# preprocesado_documents=df_preprocesado['texto_preprocesado'].apply(ast.literal_eval)    \n",
    "# documents = filter_documents_for_dictionary(preprocesado_documents, filtered_words)\n",
    "with open('recursos/documents.pkl', 'rb') as archivo:\n",
    "    documents = pickle.load(archivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daacc359",
   "metadata": {},
   "source": [
    "# En vez de frecuencia utilizar Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "335604ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "documentos_como_cadenas = [\" \".join(doc) for doc in documents]\n",
    "# Calcular TF-IDF\n",
    "tfidf_matrix = vectorizer.fit_transform(documentos_como_cadenas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "61ef25ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imprimir_documentos_relevantes_cluster_etiquetas_tfidf(etiquetas_predichas, documentos_preprocesados, documentos_originales, cluster_id, num_documentos=5, num_palabras_clave=10, mgp=None, tfidf_matrix=None, vectorizer=None):\n",
    "    # 1. Extraer palabras clave del clúster\n",
    "    palabras_clave = sorted(\n",
    "        mgp.cluster_word_distribution[cluster_id].items(),\n",
    "        key=lambda k: k[1],\n",
    "        reverse=True\n",
    "    )[:num_palabras_clave]\n",
    "\n",
    "    # 2. Obtener índices de palabras clave en la matriz TF-IDF\n",
    "    palabras_clave_ponderadas = {}\n",
    "    if vectorizer and tfidf_matrix is not None:\n",
    "        feature_names = vectorizer.get_feature_names_out() #lista de palabras (vocabulario) que fueron utilizadas\n",
    "        for palabra, _ in palabras_clave:\n",
    "            if palabra in vectorizer.vocabulary_:\n",
    "                idx = vectorizer.vocabulary_[palabra] # verifica si la palabra está en el vocabulario \n",
    "                palabras_clave_ponderadas[palabra] = np.mean(tfidf_matrix[:, idx].toarray())  # TF-IDF medio en el corpus\n",
    "\n",
    "    # 3. Evaluar documentos del clúster\n",
    "    puntuaciones_relevancia = []\n",
    "    for i, documento in enumerate(documentos_preprocesados):\n",
    "        if etiquetas_predichas[i] == cluster_id:\n",
    "            puntuacion = sum(palabras_clave_ponderadas.get(palabra, 0) for palabra in documento)\n",
    "            puntuacion /= len(documento) # Para que los documentos largos no tengan ventaja\n",
    "            puntuaciones_relevancia.append((documentos_originales[i], puntuacion))\n",
    "\n",
    "    # 4. Ordenar y mostrar documentos más relevantes\n",
    "    puntuaciones_relevancia_ordenadas = sorted(puntuaciones_relevancia, key=lambda x: x[1], reverse=True)[:num_documentos]\n",
    "\n",
    "    print(f\"Documentos más relevantes del clúster {cluster_id}:\")\n",
    "    for documento, puntuacion in puntuaciones_relevancia_ordenadas:\n",
    "        print(f\"  Documento: {documento}, Puntuación: {puntuacion}\")\n",
    "        print(\"-\" * 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fa9fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with bz2.BZ2File('recursos/documentos_originales.pkl.bz2', 'rb') as f:\n",
    "    documentos_originales = pickle.load(f)\n",
    "cluster_id =13\n",
    "imprimir_documentos_relevantes_cluster_etiquetas_tfidf(etiquetas_predichas, documents, documentos_originales, cluster_id, mgp=modelo, tfidf_matrix=tfidf_matrix, vectorizer=vectorizer,num_documentos=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d08c17b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imprimir_documentos_relevantes_cluster_etiquetas_tfidf2(etiquetas_predichas, documentos_preprocesados, documentos_originales, cluster_id, num_documentos=5, num_palabras_clave=10, mgp=None, tfidf_matrix=None, vectorizer=None):\n",
    "    # 1. Extraer palabras clave del clúster\n",
    "    palabras_clave = sorted(\n",
    "        mgp.cluster_word_distribution[cluster_id].items(),\n",
    "        key=lambda k: k[1],\n",
    "        reverse=True\n",
    "    )[:num_palabras_clave]\n",
    "\n",
    "    # 2. Obtener índices de palabras clave en la matriz TF-IDF\n",
    "    palabras_clave_ponderadas = {}\n",
    "    indices_cluster = np.where(etiquetas_predichas == cluster_id)[0]\n",
    "    if vectorizer and tfidf_matrix is not None:\n",
    "        feature_names = vectorizer.get_feature_names_out() #lista de palabras (vocabulario) que fueron utilizadas\n",
    "        for palabra, _ in palabras_clave:\n",
    "            if palabra in vectorizer.vocabulary_:\n",
    "                idx = vectorizer.vocabulary_[palabra] # verifica si la palabra está en el vocabulario \n",
    "                #palabras_clave_ponderadas[palabra] = np.mean(tfidf_matrix[:, idx].toarray())  # TF-IDF medio en el corpus\n",
    "                palabras_clave_ponderadas[palabra] = np.mean(tfidf_matrix[indices_cluster, idx].toarray()) #Calcular la media solo dentro del clúster\n",
    "\n",
    "    # 3. Evaluar documentos del clúster\n",
    "    puntuaciones_relevancia = []\n",
    "    for i, documento in enumerate(documentos_preprocesados):\n",
    "        if etiquetas_predichas[i] == cluster_id:\n",
    "            puntuacion = sum(palabras_clave_ponderadas.get(palabra, 0) for palabra in documento)\n",
    "            puntuacion /= len(documento)  # Para que los documentos largos no tengan ventaja\n",
    "            puntuaciones_relevancia.append((documentos_originales[i], puntuacion))\n",
    "\n",
    "    # 4. Ordenar y mostrar documentos más relevantes\n",
    "    puntuaciones_relevancia_ordenadas = sorted(puntuaciones_relevancia, key=lambda x: x[1], reverse=True)[:num_documentos]\n",
    "\n",
    "    print(f\"Documentos más relevantes del clúster {cluster_id}:\")\n",
    "    for documento, puntuacion in puntuaciones_relevancia_ordenadas:\n",
    "        print(f\"  Documento: {documento}, Puntuación: {puntuacion}\")\n",
    "        print(\"-\" * 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ac233b",
   "metadata": {},
   "source": [
    "# TFIDF por cluster (opción elegida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "08887311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def imprimir_documentos_relevantes_clusters(etiquetas_predichas, documentos_preprocesados, documentos_originales, top_index, num_documentos=5, nombre_archivo=\"documentos_relevantes.xlsx\"):\n",
    "      \n",
    "    resultados_totales = []\n",
    "\n",
    "    for cluster_id in top_index:\n",
    "        documentos_cluster = [(i, documentos_preprocesados[i]) for i, etiqueta in enumerate(etiquetas_predichas) if etiqueta == cluster_id]\n",
    "\n",
    "        # Calcular TF\n",
    "        tf_cluster = defaultdict(int)\n",
    "        for _, documento in documentos_cluster:\n",
    "            for palabra in documento:\n",
    "                tf_cluster[palabra] += 1\n",
    "\n",
    "        # Calcular IDF\n",
    "        palabras_por_cluster = defaultdict(set)\n",
    "        for i, etiqueta in enumerate(etiquetas_predichas):\n",
    "            palabras_por_cluster[etiqueta].update(documentos_preprocesados[i])\n",
    "\n",
    "        num_clusters = len(set(etiquetas_predichas))\n",
    "        num_clusters_con_palabra = {\n",
    "            palabra: sum(1 for palabras in palabras_por_cluster.values() if palabra in palabras)\n",
    "            for palabra in tf_cluster\n",
    "        }\n",
    "\n",
    "        idf_cluster = {palabra: np.log((1 + num_clusters) / (1 + num_clusters_con_palabra[palabra])) + 1 for palabra in tf_cluster}\n",
    "        \n",
    "        peso_palabras = {palabra: tf_cluster[palabra] * idf_cluster[palabra] for palabra in tf_cluster}\n",
    "\n",
    "        # Evaluar documentos del clúster\n",
    "        puntuaciones_relevancia = []\n",
    "        for doc_id, documento in documentos_cluster:\n",
    "            # Calcular la frecuencia relativa de cada palabra\n",
    "            total_palabras_doc = len(documento)\n",
    "            puntuacion = np.array([peso_palabras.get(palabra, 0) * (documento.count(palabra) / total_palabras_doc) for palabra in documento])\n",
    "\n",
    "            # Cortar los primeros 300 caracteres del documento original\n",
    "            documento_recortado = documentos_originales[doc_id][:300]\n",
    "\n",
    "            puntuaciones_relevancia.append((doc_id, cluster_id, documento_recortado, puntuacion_final))\n",
    "\n",
    "        # Ordenar por puntuación\n",
    "        puntuaciones_relevancia_ordenadas = sorted(puntuaciones_relevancia, key=lambda x: x[3], reverse=True)[:num_documentos]\n",
    "\n",
    "        # Añadir resultados de este cluster\n",
    "        resultados_totales.extend(puntuaciones_relevancia_ordenadas)\n",
    "\n",
    "    # Verificar que hay datos antes de crear el DataFrame\n",
    "    if resultados_totales:\n",
    "        df = pd.DataFrame(resultados_totales, columns=[\"ID\", \"ID de Cluster\", \"Documento (200 caracteres)\", \"Puntuación\"])\n",
    "\n",
    "        # Guardar en formato CSV, XLSX o ODS según el nombre de archivo\n",
    "        if nombre_archivo.endswith('.csv'):\n",
    "            df.to_csv(nombre_archivo, index=False, encoding=\"utf-8\")\n",
    "        elif nombre_archivo.endswith('.ods'):\n",
    "            df.to_excel(nombre_archivo, index=False, engine=\"odf\")\n",
    "        else:\n",
    "            df.to_excel(nombre_archivo, index=False, engine=\"openpyxl\")\n",
    "        print(f\"\\n Archivo guardado: {nombre_archivo}\")\n",
    "    else:\n",
    "        print(\"\\n No hay documentos relevantes para los clusters indicados.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be15272",
   "metadata": {},
   "outputs": [],
   "source": [
    "imprimir_documentos_relevantes_clusters(etiquetas_predichas, documents, documentos_originales, top_index, num_documentos=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6f20acb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13, 29, 60, 36, 24, 34, 19,  4, 57, 50,  3,  5,  1, 30, 48, 21, 16,\n",
       "       46,  2, 54, 31], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
