{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d19187e",
   "metadata": {},
   "source": [
    "## Obtener palabras\n",
    "modelo.show_topic(topic_id, topn=num_words)\n",
    "## Obtener documentos\n",
    "modelo.get_document_topics(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6716d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import bz2\n",
    "from IPython.display import display, HTML\n",
    "from gensim.corpora import Dictionary, MmCorpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb6d64c",
   "metadata": {},
   "source": [
    "## Seleccionar el mejor resultado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1a3eded",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('recursos/resultados_modelos.pkl', 'rb') as archivo:\n",
    "    resultados = pickle.load(archivo)\n",
    "# Para Bigramas\n",
    "# with open('recursos/resultados_modelos_bi.pkl', 'rb') as archivo:\n",
    "#     resultados = pickle.load(archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e897d850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'adjusted_rand_score': 0.16911014422085652,\n",
       "  'normalized_mutual_info_score': 0.3039122328854189,\n",
       "  'confusion_matrix': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [5, 6, 9, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 1, 1, ..., 0, 0, 0],\n",
       "         [0, 0, 1, ..., 0, 0, 0],\n",
       "         [0, 1, 0, ..., 0, 0, 0]], dtype=int64),\n",
       "  'fowlkes_mallows_score': 0.24012121098352485,\n",
       "  'bcubed_precision': 0.3497683956460666,\n",
       "  'bcubed_recall': 0.17158452253994497,\n",
       "  'bcubed_f1': 0.19114170693726434},\n",
       " {'adjusted_rand_score': 0.18742663586506847,\n",
       "  'normalized_mutual_info_score': 0.31593765619920516,\n",
       "  'confusion_matrix': array([[ 0,  0,  0, ...,  0,  0,  0],\n",
       "         [ 0,  0,  0, ...,  0,  0,  0],\n",
       "         [ 1,  5, 62, ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  5,  9, ...,  0,  0,  0],\n",
       "         [ 0,  0,  0, ...,  0,  0,  0],\n",
       "         [ 0,  0,  6, ...,  0,  0,  0]], dtype=int64),\n",
       "  'fowlkes_mallows_score': 0.2548049384456862,\n",
       "  'bcubed_precision': 0.35243559408734904,\n",
       "  'bcubed_recall': 0.19339775823371638,\n",
       "  'bcubed_f1': 0.21117702454517626},\n",
       " {'adjusted_rand_score': 0.19826718284087336,\n",
       "  'normalized_mutual_info_score': 0.31486724617523987,\n",
       "  'confusion_matrix': array([[ 0,  0,  0, ...,  0,  0,  0],\n",
       "         [ 0,  0,  0, ...,  0,  0,  0],\n",
       "         [18,  1, 55, ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [11,  0,  9, ...,  0,  0,  0],\n",
       "         [ 0,  0,  1, ...,  0,  0,  0],\n",
       "         [ 0,  0,  9, ...,  0,  0,  0]], dtype=int64),\n",
       "  'fowlkes_mallows_score': 0.26852712826783,\n",
       "  'bcubed_precision': 0.3634483627513267,\n",
       "  'bcubed_recall': 0.18946849501800506,\n",
       "  'bcubed_f1': 0.20931137901428856},\n",
       " {'adjusted_rand_score': 0.14936493018160993,\n",
       "  'normalized_mutual_info_score': 0.296685641023135,\n",
       "  'confusion_matrix': array([[ 0,  0,  0, ...,  0,  0,  0],\n",
       "         [ 0,  0,  0, ...,  0,  0,  0],\n",
       "         [ 8, 10,  7, ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  6,  0, ...,  0,  0,  0],\n",
       "         [ 0,  0,  0, ...,  0,  0,  0],\n",
       "         [ 0,  0,  0, ...,  0,  0,  0]], dtype=int64),\n",
       "  'fowlkes_mallows_score': 0.21860681831902026,\n",
       "  'bcubed_precision': 0.33891952334119396,\n",
       "  'bcubed_recall': 0.16676589595641042,\n",
       "  'bcubed_f1': 0.18029381416152931},\n",
       " {'adjusted_rand_score': 0.19680534645222264,\n",
       "  'normalized_mutual_info_score': 0.3170964324044302,\n",
       "  'confusion_matrix': array([[ 0,  0,  0, ...,  0,  0,  0],\n",
       "         [ 0,  0,  0, ...,  0,  0,  0],\n",
       "         [14,  4,  3, ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [ 0,  0,  0, ...,  0,  0,  0],\n",
       "         [ 1,  0,  0, ...,  0,  0,  0],\n",
       "         [ 0,  0,  4, ...,  0,  0,  0]], dtype=int64),\n",
       "  'fowlkes_mallows_score': 0.26710768260082085,\n",
       "  'bcubed_precision': 0.36043987223349244,\n",
       "  'bcubed_recall': 0.17993967439217942,\n",
       "  'bcubed_f1': 0.20361714528943056}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados[\"lda\"]['resultados_ejecuciones']\n",
    "#Para bigramas\n",
    "#resultados[\"lda-bi\"]['resultados_ejecuciones']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7185da95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>adjusted_rand_score</th>\n",
       "      <th>normalized_mutual_info_score</th>\n",
       "      <th>fowlkes_mallows_score</th>\n",
       "      <th>bcubed_precision</th>\n",
       "      <th>bcubed_recall</th>\n",
       "      <th>bcubed_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.169110</td>\n",
       "      <td>0.303912</td>\n",
       "      <td>0.240121</td>\n",
       "      <td>0.349768</td>\n",
       "      <td>0.171585</td>\n",
       "      <td>0.191142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.187427</td>\n",
       "      <td>0.315938</td>\n",
       "      <td>0.254805</td>\n",
       "      <td>0.352436</td>\n",
       "      <td>0.193398</td>\n",
       "      <td>0.211177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.198267</td>\n",
       "      <td>0.314867</td>\n",
       "      <td>0.268527</td>\n",
       "      <td>0.363448</td>\n",
       "      <td>0.189468</td>\n",
       "      <td>0.209311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.149365</td>\n",
       "      <td>0.296686</td>\n",
       "      <td>0.218607</td>\n",
       "      <td>0.338920</td>\n",
       "      <td>0.166766</td>\n",
       "      <td>0.180294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.196805</td>\n",
       "      <td>0.317096</td>\n",
       "      <td>0.267108</td>\n",
       "      <td>0.360440</td>\n",
       "      <td>0.179940</td>\n",
       "      <td>0.203617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lista_resultados = resultados[\"lda\"]['resultados_ejecuciones']\n",
    "# Para bigramas\n",
    "# lista_resultados = resultados[\"lda-bi\"]['resultados_ejecuciones']\n",
    "# Crear un DataFrame de pandas\n",
    "df = pd.DataFrame(lista_resultados)\n",
    "\n",
    "# Eliminar la columna 'confusion_matrix' ya que no se puede representar directamente en HTML\n",
    "df = df.drop(columns=['confusion_matrix'])\n",
    "\n",
    "# Convertir el DataFrame a HTML\n",
    "tabla_html = df.to_html(index=False)\n",
    "\n",
    "# Imprimir la tabla HTML\n",
    "display(HTML(tabla_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b41fc4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Media</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.240815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.239173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.238180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.221388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.208781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calcular la media para cada fila\n",
    "medias = df[['adjusted_rand_score', 'normalized_mutual_info_score', 'bcubed_f1']].mean(axis=1)\n",
    "\n",
    "# Añadir las medias como una nueva columna al DataFrame\n",
    "df['Media'] = medias\n",
    "\n",
    "df_ordenado = df.sort_values(by='Media',ascending=False)\n",
    "\n",
    "# Crear un nuevo dataframe solo con las medias\n",
    "df_medias = df_ordenado[['Media']]\n",
    "\n",
    "# Convertir el DataFrame a HTML\n",
    "tabla_html_medias = df_medias.to_html()\n",
    "\n",
    "display(HTML(tabla_html_medias))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e79888c",
   "metadata": {},
   "source": [
    "## Obtener las palabras más representativas de cada tópico "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1d0d939",
   "metadata": {},
   "outputs": [],
   "source": [
    "etiquetas_predichas=resultados[\"lda\"]['etiquetas_predichas'][2]\n",
    "#etiquetas_predichas=resultados[\"lda-bi\"]['etiquetas_predichas'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "626c48c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('recursos/modelos_topicos/lda_ejecucion_567.pkl', 'rb') as archivo:\n",
    "    modelo = pickle.load(archivo)\n",
    "    \n",
    "# with open('recursos/modelos_topicos_bi/lda-bi_ejecucion_1001.pkl', 'rb') as archivo:\n",
    "#     modelo = pickle.load(archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dfdbe51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los 20 tópicos con más documentos:\n",
      "  Tópico 25: 4446 documentos\n",
      "  Tópico 54: 4235 documentos\n",
      "  Tópico 28: 3987 documentos\n",
      "  Tópico 39: 3496 documentos\n",
      "  Tópico 41: 3480 documentos\n",
      "  Tópico 6: 2830 documentos\n",
      "  Tópico 47: 2658 documentos\n",
      "  Tópico 35: 2499 documentos\n",
      "  Tópico 34: 2259 documentos\n",
      "  Tópico 42: 2019 documentos\n",
      "  Tópico 49: 2006 documentos\n",
      "  Tópico 59: 1993 documentos\n",
      "  Tópico 8: 1842 documentos\n",
      "  Tópico 2: 1673 documentos\n",
      "  Tópico 58: 1593 documentos\n",
      "  Tópico 23: 1543 documentos\n",
      "  Tópico 29: 1540 documentos\n",
      "  Tópico 57: 1521 documentos\n",
      "  Tópico 9: 1441 documentos\n",
      "  Tópico 51: 1341 documentos\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Contar la cantidad de documentos para cada tópico\n",
    "topicos_documentos = defaultdict(int)\n",
    "for etiqueta in etiquetas_predichas:\n",
    "    topicos_documentos[etiqueta] += 1\n",
    "\n",
    "# Ordenar los tópicos por la cantidad de documentos (de mayor a menor)\n",
    "topicos_ordenados = sorted(topicos_documentos.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Obtener los 20 tópicos con más documentos\n",
    "top_20_topicos = topicos_ordenados[:20]\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Los 20 tópicos con más documentos:\")\n",
    "for topico_id, cantidad_documentos in top_20_topicos:\n",
    "    print(f\"  Tópico {topico_id}: {cantidad_documentos} documentos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88a4ac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "topicos_ordenados_ids = [topico_id for topico_id, cantidad_documentos in top_20_topicos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a3a392cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_palabras_topicos_excel(modelo_lda, lista_topicos, num_words=15, output_excel_path=\"palabras_topicos_lda.xlsx\"):\n",
    "    # Crear una lista para almacenar los datos de la tabla\n",
    "    data = []\n",
    "\n",
    "    # Obtener las palabras más probables para cada tópico en la lista\n",
    "    for topic_id in lista_topicos:\n",
    "        palabras_probables = modelo_lda.show_topic(topic_id, topn=num_words)\n",
    "        # Extraer solo las palabras y unirlas en una cadena separada por comas\n",
    "        palabras = [palabra for palabra, probabilidad in palabras_probables]\n",
    "        palabras_str = \", \".join(palabras)\n",
    "        # Agregar la cadena a la lista de datos\n",
    "        data.append({\"Tópico\": topic_id, \"Palabras\": palabras_str})\n",
    "\n",
    "    # Crear un DataFrame de pandas a partir de los datos\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Exportar el DataFrame a un archivo Excel\n",
    "    df.to_excel(output_excel_path, index=False)\n",
    "\n",
    "    print(f\"Las palabras de los tópicos se han exportado a '{output_excel_path}'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "62ed6781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las palabras de los tópicos se han exportado a 'palabras_topicos_lda.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "generar_palabras_topicos_excel(modelo, topicos_ordenados_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efa3f13",
   "metadata": {},
   "source": [
    "### Generar los documentos más relevantes de un tópico "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50c547bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def generar_documentos_topicos_excel(modelo_lda, corpus, documentos, lista_topicos, output_excel_path=\"documentos_topicos_lda.xlsx\"):\n",
    "    \"\"\"\n",
    "    Genera un archivo Excel donde cada fila representa un documento, y las columnas representan las probabilidades\n",
    "    de que dicho documento pertenezca a cada uno de los tópicos de la lista proporcionada.\n",
    "    Solo se incluyen los 5 documentos más relevantes por cada tópico.\n",
    "    \n",
    "    Args:\n",
    "        modelo_lda: El modelo LDA entrenado.\n",
    "        corpus: El corpus de documentos procesados.\n",
    "        documentos: Lista de los documentos originales.\n",
    "        lista_topicos: Lista de los IDs de los tópicos de interés.\n",
    "        output_excel_path: Ruta del archivo Excel de salida.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Crear una lista para almacenar los datos de la tabla\n",
    "    data = []\n",
    "\n",
    "    # Recorrer cada tópico de la lista de tópicos\n",
    "    for topic_id in lista_topicos:\n",
    "        documentos_topicos = []\n",
    "\n",
    "        # Recorrer cada documento\n",
    "        for doc_id, doc in enumerate(corpus):\n",
    "            # Obtener la distribución de tópicos para el documento\n",
    "            distribucion_topicos = modelo_lda.get_document_topics(doc)\n",
    "            \n",
    "            # Buscar la probabilidad del tópico deseado\n",
    "            probabilidad_topico = 0\n",
    "            for topico, probabilidad in distribucion_topicos:\n",
    "                if topico == topic_id:\n",
    "                    probabilidad_topico = probabilidad\n",
    "                    break\n",
    "            \n",
    "            # Agregar el documento y su probabilidad del tópico\n",
    "            documentos_topicos.append((doc_id, probabilidad_topico))\n",
    "\n",
    "        # Ordenar los documentos por la probabilidad del tópico (de mayor a menor)\n",
    "        documentos_ordenados = sorted(documentos_topicos, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Obtener los 5 documentos más relevantes para el tópico\n",
    "        top_5_documentos = documentos_ordenados[:5]\n",
    "\n",
    "        # Agregar los datos al archivo Excel\n",
    "        for doc_id, probabilidad in top_5_documentos:\n",
    "            contenido_documento = documentos[doc_id][:300]  # Tomamos los primeros 300 caracteres del documento\n",
    "            data.append({\"Documento\": contenido_documento, f\"Tópico_{topic_id}\": probabilidad})\n",
    "\n",
    "    # Crear un DataFrame de pandas a partir de los datos\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Exportar el DataFrame a un archivo Excel\n",
    "    df.to_excel(output_excel_path, index=False)\n",
    "\n",
    "    print(f\"Los documentos más relevantes por tópico se han exportado a '{output_excel_path}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "581ebfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_preprocesado = pd.read_csv('df_preprocesado.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5512ef8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los documentos más relevantes por tópico se han exportado a 'documentos_topicos_lda.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "#documentos=df_preprocesado['texto']\n",
    "with bz2.BZ2File('recursos/documentos_originales.pkl.bz2', 'rb') as f:\n",
    "    documentos = pickle.load(f)\n",
    "corpus = MmCorpus('recursos/corpus.mm')\n",
    "generar_documentos_topicos_excel(modelo,corpus,documentos,topicos_ordenados_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
